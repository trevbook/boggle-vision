{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Motivation\n",
    "I want to try my hand at training a CNN for letter recognition sometime soon. In order to do that, I'm going to need to collect some training data. \n",
    "\n",
    "This notebook will parse through all of the labeled images I have, extract the processed tile images, and then save them as separate images. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup\n",
    "The cells below will set up the rest of this notebook. \n",
    "\n",
    "I'll start by configuring the kernel: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d:\\data\\programming\\boggle-vision\n"
     ]
    }
   ],
   "source": [
    "# Change directories to the root of the project\n",
    "%cd ..\n",
    "\n",
    "# Enable autoreload of modules\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, I'm going to import some relevant libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import statements\n",
    "import cv2\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import math\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "from statistics import mode\n",
    "import utils\n",
    "import cv2\n",
    "import pytesseract\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "import shutil\n",
    "\n",
    "# Importing custom modules\n",
    "import utils.board_detection as board_detect"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, I'm going to create a folder in the `data/` folder - this is where I'll store all of the data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Declare the path to the training-data folder\n",
    "training_data_path = Path(\"data/training-data\")\n",
    "\n",
    "# If it already exists, delete it (even if it's not empty)\n",
    "if training_data_path.exists():\n",
    "    shutil.rmtree(training_data_path)\n",
    "\n",
    "# Create the training-data folder\n",
    "training_data_path.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading Data\n",
    "Here, I'm going to load in all of the pictures, as well as some information about each of them. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open the .csv file containing the labeled boards\n",
    "board_data_df = pd.read_csv(\"data/labeled-boards.csv\")\n",
    "\n",
    "# Add a column which is the parsed letter sequence\n",
    "board_data_df[\"parsed_letter_sequence\"] = board_data_df[\"letter_sequence\"].apply(\n",
    "    lambda letter_list: letter_list.split(\";\")\n",
    ")\n",
    "\n",
    "# Load all of the images using cv2\n",
    "file_path_to_image = {}\n",
    "for row in board_data_df.itertuples():\n",
    "    file_path_to_image[row.file_path] = cv2.imread(row.file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parsing Boards\n",
    "Below, I'm going to run each of the boards through a \"parsing\" method. This will extract the \"processed\" letter images for each of the different tiles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8/8 [00:03<00:00,  2.20it/s]\n"
     ]
    }
   ],
   "source": [
    "# We'll collect some results about the board data here\n",
    "all_parsed_boards_df_records = []\n",
    "\n",
    "# Iterate through all of the rows in the board data\n",
    "for row in tqdm(list(board_data_df.query(\"difficulty == 'easy'\").itertuples())):\n",
    "    # Try and parse the board\n",
    "    error_msg = None\n",
    "    try:\n",
    "        letter_img_sequence = board_detect.parse_boggle_board(\n",
    "            file_path_to_image[row.file_path],\n",
    "            max_image_height=1200,\n",
    "            return_parsed_img_sequence=True\n",
    "        )\n",
    "\n",
    "    except Exception as e:\n",
    "        continue\n",
    "\n",
    "    # Add some information to the all_parsed_boards_df_records\n",
    "    all_parsed_boards_df_records.append(\n",
    "        {\n",
    "            \"file_path\": row.file_path,\n",
    "            \"letter_img_sequence\": letter_img_sequence,\n",
    "            \"error_msg\": error_msg,\n",
    "        }\n",
    "    )\n",
    "\n",
    "# Parse the results into a dataframe\n",
    "all_parsed_boards_df = pd.DataFrame(all_parsed_boards_df_records)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Associating Images with Letters\n",
    "Finally, I'm going to create a final DataFrame, where each row represents a single tile from a test image. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8/8 [00:00<00:00, 66.30it/s]\n"
     ]
    }
   ],
   "source": [
    "# We're going to store each row of the eventual DataFrame in this list \n",
    "parsed_letter_img_df_records = []\n",
    "\n",
    "# Iterate through each row in the parsed boards DataFrame\n",
    "for row in tqdm(list(all_parsed_boards_df.merge(board_data_df, on=\"file_path\").itertuples())):\n",
    "    \n",
    "    # Extract some information about the current board\n",
    "    cur_board_file_path = Path(row.file_path)\n",
    "    cur_board_letter_sequence = row.parsed_letter_sequence\n",
    "    cur_board_letter_img_sequence = row.letter_img_sequence\n",
    "    \n",
    "    # Iterate through each of the letters in the parsed letter sequence\n",
    "    for tile_idx, letter in enumerate(cur_board_letter_sequence):\n",
    "        \n",
    "        # Determine the image associated with the current tile_idx\n",
    "        cur_tile_img = cur_board_letter_img_sequence.get(tile_idx, None)\n",
    "        if cur_tile_img is None:\n",
    "            continue\n",
    "        \n",
    "        # Save the current tile image to the training-data directory\n",
    "        cur_tile_img_file_path = training_data_path / f\"{letter}_{cur_board_file_path.stem}_{tile_idx}.png\"\n",
    "        cv2.imwrite(str(cur_tile_img_file_path), cur_tile_img)\n",
    "        \n",
    "        # Store the information about the current tile in the parsed_letter_img_df_records\n",
    "        parsed_letter_img_df_records.append(\n",
    "            {\n",
    "                \"board_img_file_path\": cur_board_file_path,\n",
    "                \"tile_idx\": tile_idx,\n",
    "                \"letter\": letter,\n",
    "                \"tile_img\": cur_tile_img,\n",
    "                \"tile_img_file_path\": cur_tile_img_file_path,\n",
    "            }\n",
    "        )\n",
    "\n",
    "# Now, make a DataFrame from the parsed_letter_img_df_records\n",
    "parsed_letter_img_df = pd.DataFrame(parsed_letter_img_df_records)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, with this DataFrame created, we're going to drop the images from it and then save it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the index (i.e., a list of all of the tile images) to an Excel file\n",
    "parsed_letter_img_df.drop(columns=[\"tile_img\"]).to_excel(\n",
    "    \"data/training-data/index.xlsx\", index=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're also going to save some stats; this will be a count of how many of each tile we have. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine the count of each tile in the dataset\n",
    "original_tile_count_df = (\n",
    "    parsed_letter_img_df.drop(columns=[\"tile_img\"])\n",
    "    .groupby(\"letter\")\n",
    "    .agg(count=(\"tile_idx\", \"count\"))\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "# Ensure that all of the tile types are represented\n",
    "from utils.settings import allowed_boggle_tiles\n",
    "\n",
    "# Create a DataFrame to store the tile counts\n",
    "tile_count_df_records = []\n",
    "for tile in allowed_boggle_tiles:\n",
    "    if tile not in original_tile_count_df[\"letter\"].values:\n",
    "        tile_count_df_records.append(\n",
    "            {\n",
    "                \"letter\": tile,\n",
    "                \"count\": 0,\n",
    "            }\n",
    "        )\n",
    "    else:\n",
    "        tile_count_df_records.append(\n",
    "            {\n",
    "                \"letter\": tile,\n",
    "                \"count\": original_tile_count_df.query(f\"letter == '{tile}'\")[\n",
    "                    \"count\"\n",
    "                ].values[0],\n",
    "            }\n",
    "        )\n",
    "tile_count_df = pd.DataFrame(tile_count_df_records)\n",
    "\n",
    "# Store the tile counts in an Excel file\n",
    "tile_count_df.to_excel(\"data/training-data/stats.xlsx\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
