{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Motivation\n",
    "After playing around with a couple of off-the-shelf OCR engines, I decided to try my hand at creating my own model. I want something that's lightweight and accurate.\n",
    "\n",
    "In this notebook, I'm going to try my hand at training a convolutional neural network to detect Boggle letters. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup\n",
    "The cells below will set up the rest of the notebook. \n",
    "\n",
    "I'll start by configuring the kernel: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d:\\data\\programming\\boggle-vision\n"
     ]
    }
   ],
   "source": [
    "# Change the directory to the root of the repo \n",
    "%cd ..\n",
    "\n",
    "# Enable the autoreload extension\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that the kernel is configured, I'm going to load in some modules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# General import statements\n",
    "import os\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Pytorch-related import statements\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision.io import read_image\n",
    "from torch.utils.data import random_split\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "# Importing custom modules from this repo\n",
    "from utils.settings import allowed_boggle_tiles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading Data\n",
    "I'm going to start by creating a custom `Dataset` for my network, and by specifying a `DataLoader`. Since it's been a bit, I'm going to follow [the Pytorch documentation](https://pytorch.org/tutorials/beginner/basics/data_tutorial.html#creating-a-custom-dataset-for-your-files) for this.\n",
    "\n",
    "I'll start with the `Dataset`, which I'll call a `BoggleTileImageDataset`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BoggleTileImageDataset(Dataset):\n",
    "    \"\"\"\n",
    "    This is a custom Dataset for handling the Boggle tile images.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, image_directory):\n",
    "        \"\"\"\n",
    "        This is the initialization method. Here, I'll set some class variables\n",
    "        for the image directory and the image paths.\n",
    "        \"\"\"\n",
    "\n",
    "        # Set the img_dir class variable\n",
    "        self.img_dir = image_directory\n",
    "        \n",
    "        # Create a mapping of letters to integers\n",
    "        self.letter_to_int_dict = {letter: idx for idx, letter in enumerate(allowed_boggle_tiles)}\n",
    "\n",
    "        # Create a class variable mapping each of the image paths to their labels\n",
    "        self.img_path_to_label_dict = {}\n",
    "        for child_file in Path(image_directory).iterdir():\n",
    "            if child_file.suffix == \".png\":\n",
    "                cur_file_letter = child_file.name.split(\"_\")[0]\n",
    "                self.img_path_to_label_dict[child_file] = cur_file_letter\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"\n",
    "        This method will return the length of the dataset.\n",
    "        \"\"\"\n",
    "        return len(self.img_path_to_label_dict)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\"\n",
    "        This method will return the image and the label for a given index.\n",
    "        \"\"\"\n",
    "        img_path = list(self.img_path_to_label_dict.keys())[idx]\n",
    "        img = read_image(str(img_path)).float()\n",
    "        label = self.img_path_to_label_dict[img_path]\n",
    "        label_int = self.letter_to_int_dict[label]\n",
    "        label = torch.tensor(label_int)\n",
    "        return img, label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With this custom `Dataset` in hand, I'm going to create an instance of it (as well as an accompanying `DataLoader`).  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading in the full dataset\n",
    "full_dataset = BoggleTileImageDataset(\"data/training-data\")\n",
    "\n",
    "# Calculate lengths for each split\n",
    "train_length = int(0.93 * len(full_dataset))\n",
    "val_length = int(0.05 * len(full_dataset))\n",
    "test_length = len(full_dataset) - train_length - val_length\n",
    "\n",
    "# Split the dataset\n",
    "train_data, val_data, test_data = random_split(full_dataset, [train_length, val_length, test_length])\n",
    "\n",
    "# Create DataLoaders\n",
    "batch_size = 256\n",
    "train_loader = DataLoader(train_data, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_data, batch_size=batch_size, shuffle=False)\n",
    "test_loader = DataLoader(test_data, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**MISC:** Below, I can show one of the images from the training data, as well as its corresponding label:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature batch shape: torch.Size([256, 1, 100, 100])\n",
      "Labels batch shape: torch.Size([256])\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label: 10 (K)\n"
     ]
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "train_features, train_labels = next(iter(train_loader))\n",
    "print(f\"Feature batch shape: {train_features.size()}\")\n",
    "print(f\"Labels batch shape: {train_labels.size()}\")\n",
    "img = train_features[0].squeeze()\n",
    "label = train_labels[0]\n",
    "plt.imshow(img, cmap=\"gray\")\n",
    "plt.show()\n",
    "print(f\"Label: {label} ({allowed_boggle_tiles[label]})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Defining Network Architecture\n",
    "Next, I'm going to define an architecture for the network. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BoggleCNN(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(BoggleCNN, self).__init__()\n",
    "        \n",
    "        # Convolutional layers\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv2d(1, 32, kernel_size=3),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2),\n",
    "            \n",
    "            nn.Conv2d(32, 64, kernel_size=3),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2)\n",
    "        )\n",
    "        \n",
    "        # Placeholder for the feature map size, to be filled in later\n",
    "        self.feature_map_size = None \n",
    "        \n",
    "        # Fully connected layers\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(1, 128),  # Placeholder size, will adjust dynamically\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, num_classes)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.features(x)  # Pass through the convolutional layers\n",
    "        \n",
    "        # Dynamically calculate the feature map size if not done already\n",
    "        if self.feature_map_size is None:\n",
    "            self.feature_map_size = x.size(1) * x.size(2) * x.size(3)\n",
    "            self.classifier[0] = nn.Linear(self.feature_map_size, 128)  # Adjust the FC layer size\n",
    "            \n",
    "        x = x.view(x.size(0), -1)  # Flatten the tensor\n",
    "        x = self.classifier(x)     # Pass through the fully connected layers\n",
    "        return x\n",
    "    \n",
    "class EnhancedBoggleCNN(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(EnhancedBoggleCNN, self).__init__()\n",
    "        \n",
    "        # More Convolutional layers\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv2d(1, 32, kernel_size=3),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2),\n",
    "            \n",
    "            nn.Conv2d(32, 64, kernel_size=3),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2),\n",
    "            \n",
    "            nn.Conv2d(64, 128, kernel_size=3),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2),\n",
    "            \n",
    "            nn.Conv2d(128, 256, kernel_size=3),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2)\n",
    "        )\n",
    "        \n",
    "        # Placeholder for the feature map size, to be filled in later\n",
    "        self.feature_map_size = None\n",
    "        \n",
    "        # More Fully connected layers\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(1, 256),  # Placeholder size, will adjust dynamically\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),  # Added Dropout to prevent overfitting\n",
    "            \n",
    "            nn.Linear(256, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),  # Added Dropout to prevent overfitting\n",
    "            \n",
    "            nn.Linear(128, num_classes)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        \n",
    "        # Dynamically calculate the feature map size\n",
    "        if self.feature_map_size is None:\n",
    "            self.feature_map_size = x.size(1) * x.size(2) * x.size(3)\n",
    "            self.classifier[0] = nn.Linear(self.feature_map_size, 256)\n",
    "            \n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.classifier(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "# Create the model\n",
    "model = EnhancedBoggleCNN(num_classes=len(allowed_boggle_tiles))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're also going to define a loss function and optimizer: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the loss function and optimizer\n",
    "loss_function = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Loop\n",
    "Next, I'm going to run through the training loop:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 45/45 [01:19<00:00,  1.77s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 loss: 2.9983075168397693\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 45/45 [00:57<00:00,  1.28s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 loss: 0.9846450726191203\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 45/45 [01:03<00:00,  1.40s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3 loss: 0.37852620085080463\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 45/45 [01:04<00:00,  1.43s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4 loss: 0.19647077967723212\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 45/45 [01:05<00:00,  1.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5 loss: 0.14040122876564662\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Iterate through the data \n",
    "epoch_amt = 5\n",
    "for epoch in range(epoch_amt):\n",
    "    \n",
    "    # We're going to keep track of the loss for each epoch\n",
    "    epoch_loss = 0\n",
    "    \n",
    "    # Iterate through the data\n",
    "    for (data, target) in tqdm(train_loader):\n",
    "        \n",
    "        # Zero out the gradients\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Make predictions\n",
    "        output = model(data)\n",
    "        \n",
    "        # Calculate the loss\n",
    "        loss = loss_function(output, target)\n",
    "        \n",
    "        # Backpropagate the loss\n",
    "        loss.backward()\n",
    "        \n",
    "        # Update the parameters\n",
    "        optimizer.step()\n",
    "        \n",
    "        # Add the loss to the epoch loss\n",
    "        epoch_loss += loss.item()\n",
    "        \n",
    "    # Print the epoch loss\n",
    "    print(f\"Epoch {epoch + 1} loss: {epoch_loss / len(train_loader)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing Loop \n",
    "Now that we've got a trained model, we ought to test it on the test data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on the test set: 0.97165991902834\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Calculate the accuracy on the test set\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "# Iterate through the test set\n",
    "for (data, target) in tqdm(test_loader):\n",
    "        \n",
    "        # Make predictions\n",
    "        output = model(data)\n",
    "        \n",
    "        # Get the predicted class\n",
    "        _, predicted = torch.max(output.data, 1)\n",
    "        \n",
    "        # Add the number of correct predictions to the total correct\n",
    "        total += target.size(0)\n",
    "        correct += (predicted == target).sum().item()\n",
    "\n",
    "# Print the accuracy\n",
    "print(f\"Accuracy on the test set: {correct / total}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving the Model\n",
    "Now that we've created a model, we ought to save it to disk. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a path to save the model\n",
    "model_folder = Path(\"models\")\n",
    "model_folder.mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "# Save the model\n",
    "torch.save(model.state_dict(), model_folder / \"boggle_cnn.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
