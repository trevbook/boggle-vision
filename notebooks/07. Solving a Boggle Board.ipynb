{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Motivation\n",
    "Now, for a very different type of notebook: I'm leaving the realm of computer vision, and moving into some algorithm design. In this notebook, I'll write an algorithm to solve a Boggle board. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup\n",
    "The cells below will set up the rest of the notebook. \n",
    "\n",
    "I'll start by configuring the kernel:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d:\\data\\programming\\boggle-vision\n"
     ]
    }
   ],
   "source": [
    "# Change directories to the root of the project\n",
    "%cd ..\n",
    "\n",
    "# Enable autoreload of modules\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, I'm going to import various modules:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import statements\n",
    "import json\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Import custom-built modules\n",
    "from utils.settings import allowed_boggle_tiles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I'm also going to load in the dictionary of allowed words:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load in the list of allowed words\n",
    "with open(\"data\\scrabble-dictionary.json\", \"r\") as json_file:\n",
    "    allowed_words = json.load(json_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Methods\n",
    "Below, I'll define a number of methods. \n",
    "\n",
    "This first one will build [a trie](https://en.wikipedia.org/wiki/Trie). This is an efficient data structure for string search, apparently.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def insert_word(node, word, allowed_tiles, index=0):\n",
    "    if index == len(word):\n",
    "        node[\"end\"] = True\n",
    "        return\n",
    "\n",
    "    for tile in allowed_tiles:\n",
    "        if word.startswith(tile, index):\n",
    "            next_node = node.setdefault(tile, {})\n",
    "            insert_word(next_node, word, allowed_tiles, index + len(tile))\n",
    "\n",
    "def build_trie(allowed_words, allowed_tiles):\n",
    "    root = {}\n",
    "    for word in allowed_words:\n",
    "        insert_word(root, word, allowed_tiles)\n",
    "    return root"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next method will parse a Boggle board from a semicolon-delimited letter sequence:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_board_from_letter_sequence(letter_sequence):\n",
    "    \"\"\"\n",
    "    This method will parse a Boggle board (in the form of a 2D list)\n",
    "    from a sequence of semi-colon delimited letters.\n",
    "    \"\"\"\n",
    "    board = []\n",
    "    split_letter_sequence = letter_sequence.split(\";\")\n",
    "    n_rows = int(len(split_letter_sequence) ** 0.5)\n",
    "    for i in range(n_rows):\n",
    "        board.append(split_letter_sequence[i*n_rows:(i+1)*n_rows])\n",
    "    return board"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next method will score a word depending on its length."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def score_boggle_word(word):\n",
    "    \"\"\"\n",
    "    This method will score a Boggle word.\n",
    "    \"\"\"\n",
    "\n",
    "    if len(word) < 4:\n",
    "        return 0\n",
    "    elif len(word) == 4:\n",
    "        return 1\n",
    "    elif len(word) == 5:\n",
    "        return 2\n",
    "    elif len(word) == 6:\n",
    "        return 3\n",
    "    elif len(word) == 7:\n",
    "        return 5\n",
    "    else:\n",
    "        return 11"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These next couple of methods were generated by ChatGPT - they'll help me solve the Boggle boards:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if a position is within the Boggle board\n",
    "def is_valid(x, y, visited, board):\n",
    "    return 0 <= x < len(board) and 0 <= y < len(board[0]) and not visited[x][y]\n",
    "\n",
    "\n",
    "# Run DFS on the board to find words\n",
    "def dfs(x, y, board, visited, trie, word, found_words):\n",
    "    if trie.get(\"end\"):\n",
    "        found_words.add(word)\n",
    "\n",
    "    visited[x][y] = True\n",
    "\n",
    "    # Adjacent positions (up, down, left, right, and diagonals)\n",
    "    directions = [(-1, -1), (-1, 0), (-1, 1), (0, -1), (0, 1), (1, -1), (1, 0), (1, 1)]\n",
    "\n",
    "    for dx, dy in directions:\n",
    "        new_x, new_y = x + dx, y + dy\n",
    "        if is_valid(new_x, new_y, visited, board) and board[new_x][new_y] != \"block\":\n",
    "            next_char = board[new_x][new_y]\n",
    "            if next_char in trie:\n",
    "                dfs(\n",
    "                    new_x,\n",
    "                    new_y,\n",
    "                    board,\n",
    "                    visited,\n",
    "                    trie[next_char],\n",
    "                    word + next_char,\n",
    "                    found_words,\n",
    "                )\n",
    "\n",
    "    visited[x][y] = False\n",
    "\n",
    "\n",
    "# Solve the Boggle board\n",
    "def solve_boggle(board, trie):\n",
    "    found_words = set()\n",
    "\n",
    "    rows, cols = len(board), len(board[0])\n",
    "    visited = [[False for _ in range(cols)] for _ in range(rows)]\n",
    "\n",
    "    for i in range(rows):\n",
    "        for j in range(cols):\n",
    "            start_char = board[i][j]\n",
    "            if start_char in trie:\n",
    "                dfs(\n",
    "                    i,\n",
    "                    j,\n",
    "                    board,\n",
    "                    visited,\n",
    "                    trie[start_char],\n",
    "                    start_char,\n",
    "                    found_words,\n",
    "                )\n",
    "\n",
    "    # Now, we're going to create a DataFrame that contains the words found on each board\n",
    "    available_words_df = pd.DataFrame.from_records(\n",
    "        [\n",
    "            {\"word\": word, \"length\": len(word), \"points\": score_boggle_word(word)}\n",
    "            for word in found_words\n",
    "        ]\n",
    "    ).sort_values(\"length\", ascending=False)\n",
    "\n",
    "    return available_words_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main Loop\n",
    "Below, I'm going to load in all of the Boggle boards, and then solve them. I'll start by loading them in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open the .csv file containing the labeled boards\n",
    "board_data_df = pd.read_csv(\"data/labeled-boards.csv\")\n",
    "\n",
    "# Convert all of the letters to lowercase\n",
    "board_data_df[\"letter_sequence\"] = board_data_df[\"letter_sequence\"].str.lower()\n",
    "\n",
    "# Parse the boards from the letter sequences\n",
    "board_data_df[\"board\"] = board_data_df[\"letter_sequence\"].apply(\n",
    "    parse_board_from_letter_sequence\n",
    ")\n",
    "\n",
    "# Create a trie out of the allowed words\n",
    "allowed_words_trie = build_trie(\n",
    "    [x.lower() for x in allowed_words],\n",
    "    [x.lower() for x in allowed_boggle_tiles if x != \"block\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that I've got each of the boards, I can run board detection on them. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/40 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 40/40 [00:00<00:00, 206.24it/s]\n"
     ]
    }
   ],
   "source": [
    "# Now, create a dictionary mapping image names to DataFrames containing the\n",
    "# allowed words and their scores\n",
    "board_data_dfs = {}\n",
    "for row in tqdm(list(board_data_df.itertuples())):\n",
    "    board_data_dfs[row.file_path] = solve_boggle(row.board, allowed_words_trie)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, I'm going to calculate some stats about each board, and add them to a DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This list will hold DataFrame records\n",
    "solved_board_stats_df_records = []\n",
    "\n",
    "# Iterate through each of the boards\n",
    "for board_file_path, solved_board_df in board_data_dfs.items():\n",
    "    # Determine how many words are worth 11 points\n",
    "    max_point_word_ct = len(solved_board_df.query(\"points==11\"))\n",
    "\n",
    "    # Determine how many points are available on the board\n",
    "    max_points = solved_board_df[\"points\"].sum()\n",
    "\n",
    "    # Store the stats in a dictionary\n",
    "    solved_board_stats_df_records.append(\n",
    "        {\n",
    "            \"file_path\": board_file_path,\n",
    "            \"max_point_word_ct\": max_point_word_ct,\n",
    "            \"max_points\": max_points,\n",
    "        }\n",
    "    )\n",
    "\n",
    "# Create a DataFrame from the records\n",
    "solved_board_stats_df = pd.DataFrame.from_records(solved_board_stats_df_records)\n",
    "\n",
    "# Merge the solved board stats with the original board data\n",
    "solved_board_stats_df = board_data_df.merge(\n",
    "    solved_board_stats_df, on=\"file_path\"\n",
    ").sort_values(\"max_points\", ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\n",
      "    \"a\",\n",
      "    \"n\",\n",
      "    \"d\",\n",
      "    \"t\",\n",
      "    \"a\",\n",
      "    \"p\",\n",
      "    \"n\",\n",
      "    \"o\",\n",
      "    \"r\",\n",
      "    \"t\",\n",
      "    \"h\",\n",
      "    \"u\",\n",
      "    \"i\",\n",
      "    \"l\",\n",
      "    \"u\",\n",
      "    \"s\",\n",
      "    \"e\",\n",
      "    \"e\",\n",
      "    \"t\",\n",
      "    \"c\",\n",
      "    \"o\",\n",
      "    \"s\",\n",
      "    \"r\",\n",
      "    \"a\",\n",
      "    \"a\",\n",
      "    \"a\",\n",
      "    \"z\",\n",
      "    \"c\",\n",
      "    \"o\",\n",
      "    \"er\",\n",
      "    \"k\",\n",
      "    \"e\",\n",
      "    \"n\",\n",
      "    \"r\",\n",
      "    \"s\",\n",
      "    \"i\"\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "mylist = solved_board_stats_df.iloc[0].letter_sequence.split(\";\")\n",
    "\n",
    "# Print each of the strings in mylist, but use quotation marks \n",
    "# around each string (so that it's a valid JSON list)\n",
    "print(json.dumps(mylist, indent=4, sort_keys=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving the Trie\n",
    "Now that I've created the trie, I'm going to save it for later use. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"data/allowed-words-trie.json\", \"w\") as json_file:\n",
    "    json.dump(allowed_words_trie, json_file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
