{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Motivation\n",
    "In this notebook, I'm going to analyze the results of some of the Boggle simulation runs I produced in **Notebook 10: Simulating Bogglel Games**. My laptop's RAM sort of dies out on 1mil+ game simulation runs, so in order to actually analyze things in large scale, I'll need to combine the results of training runs. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup\n",
    "The cells below will set up the rest of the notebook. \n",
    "\n",
    "I'll start by configuring my kernel:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d:\\data\\programming\\boggle-vision\\boggle-vision-prototyping\n"
     ]
    }
   ],
   "source": [
    "# Change the cwd to the root of the project\n",
    "%cd ..\n",
    "\n",
    "# Enable the autoreload of modules\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, I'm going to import some necessary libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import general modules\n",
    "import pandas as pd\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "from pathlib import Path\n",
    "import datetime\n",
    "import plotly.express as px\n",
    "\n",
    "# Importing custom-built modules\n",
    "from utils.board_solving import (\n",
    "    parse_board_from_letter_sequence,\n",
    "    solve_boggle,\n",
    "    allowed_words_trie,\n",
    "    score_boggle_word\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading Data\n",
    "First, I'm going to load all of the simulation results I've produced up until now. \n",
    "\n",
    "I've saved `.json` files containing aggregated simulation word counts. I'll load all of them in below, and parse them as I load them. \n",
    "\n",
    "Once each of the games are loaded, I'll add some extra columns. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 13/13 [00:02<00:00,  4.34it/s]\n"
     ]
    }
   ],
   "source": [
    "# Iterate through each .json file in the data/simulations folder\n",
    "total_games = 0\n",
    "word_ct_dict = {}\n",
    "for path in tqdm(list(Path(\"data/simulations\").glob(\"*.json\"))):\n",
    "    # Load the data\n",
    "    with open(path, \"r\") as f:\n",
    "        data = json.load(f)\n",
    "\n",
    "    # Add the number of games to the total\n",
    "    total_games += data.get(\"n_games\", 0)\n",
    "\n",
    "    # Iterate through each of the words in the word_ct dict\n",
    "    for word, ct in data.get(\"word_ct\", []):\n",
    "        # Add the word to the word_ct_dict\n",
    "        word_ct_dict[word] = word_ct_dict.get(word, 0) + ct\n",
    "\n",
    "# Make a DataFrame of the word_ct_dict\n",
    "simulation_df = pd.DataFrame.from_records(\n",
    "    [(word, ct) for word, ct in word_ct_dict.items()], columns=[\"word\", \"ct\"]\n",
    ")\n",
    "\n",
    "# Add some additional columns\n",
    "simulation_df[\"length\"] = simulation_df[\"word\"].apply(len)\n",
    "simulation_df[\"points\"] = simulation_df[\"word\"].apply(score_boggle_word)\n",
    "\n",
    "# Determine the percentage of games that each word was found in\n",
    "simulation_df[\"pct_games\"] = simulation_df[\"ct\"] / total_games\n",
    "\n",
    "# Calculate the z-score of each word\n",
    "simulation_df[\"z_score\"] = (\n",
    "    simulation_df[\"pct_games\"] - simulation_df[\"pct_games\"].mean()\n",
    ") / simulation_df[\"pct_games\"].std()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that I've added all of those stats, I'm going to assign a \"rarity\" to the word. I've created the thresholds after a little manual inspection of the z-score distribution! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "rarity\n",
       "Very Rare    86467\n",
       "Rare         40731\n",
       "Common       23527\n",
       "Uncommon     14027\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This method will determine if a word is \"Common\", \"Uncommon\", \"Rare\", and \"Very Rare\"\n",
    "def categorize_word(z_score):\n",
    "    \"\"\"\n",
    "    Categorize a word based on its z-score.\n",
    "\n",
    "    :param z_score: The z-score of the word\n",
    "    :return: The category of the word ('Common', 'Uncommon', 'Rare', 'Very Rare')\n",
    "    \"\"\"\n",
    "    if z_score > 0:\n",
    "        return \"Common\"\n",
    "    elif z_score > -0.15:\n",
    "        return \"Uncommon\"\n",
    "    elif z_score > -0.23:\n",
    "        return \"Rare\"\n",
    "    else:\n",
    "        return \"Very Rare\"\n",
    "    \n",
    "    \n",
    "# Apply the word_rarity function to the DataFrame\n",
    "simulation_df[\"rarity\"] = simulation_df[\"z_score\"].apply(categorize_word)\n",
    "\n",
    "# Print out the summary statistics of the rarity\n",
    "simulation_df[\"rarity\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving Data\n",
    "Now that I've calculated all of this information about the words, I'd like to save it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a dictionary, keyed by the word, of all of the rarity stats from the simulation_df\n",
    "rarity_dict = simulation_df.set_index(\"word\").to_dict(orient=\"index\")\n",
    "\n",
    "# Now, save a dictionary with both the rarity_dict and the total_games\n",
    "with open(\"data/word_rarity.json\", \"w\") as f:\n",
    "    json.dump({\"rarity_dict\": rarity_dict, \"total_games\": total_games}, f, indent=2)\n",
    "\n",
    "\n",
    "with open(\"../boggle-vision-app/boggle-vision-api/data/word_rarity.json\", \"w\") as f:\n",
    "    json.dump({\"rarity_dict\": rarity_dict, \"total_games\": total_games}, f, indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
