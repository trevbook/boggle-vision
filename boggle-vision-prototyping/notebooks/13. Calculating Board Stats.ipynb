{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Motivation\n",
    "In this notebook, I'm going to analyze the results of some of the Boggle simulation runs I produced in **Notebook 10: Simulating Bogglel Games**. My laptop's RAM sort of dies out on 1mil+ game simulation runs, so in order to actually analyze things in large scale, I'll need to combine the results of training runs. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup\n",
    "The cells below will set up the rest of the notebook. \n",
    "\n",
    "I'll start by configuring my kernel:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d:\\data\\programming\\boggle-vision\\boggle-vision-prototyping\n"
     ]
    }
   ],
   "source": [
    "# Change the cwd to the root of the project\n",
    "%cd ..\n",
    "\n",
    "# Enable the autoreload of modules\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, I'm going to import some necessary libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import general modules\n",
    "import pandas as pd\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "from pathlib import Path\n",
    "import datetime\n",
    "\n",
    "# Importing custom-built modules\n",
    "from utils.board_solving import (\n",
    "    parse_board_from_letter_sequence,\n",
    "    solve_boggle,\n",
    "    allowed_words_trie,\n",
    "    score_boggle_word\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading Data\n",
    "First, I'm going to load all of the simulation results I've produced up until now. \n",
    "\n",
    "Each of the simulations is saved as a DataFrame JSON `(orient=\"records\")`. When I load each of them in, I'll also add back the columns that I stripped - `points` and `length`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 1/2 [00:13<00:13, 13.60s/it]"
     ]
    }
   ],
   "source": [
    "# Declaring the path to the data folder\n",
    "simulation_data_path = \"data/simulations/\"\n",
    "\n",
    "# Iterate through the simulation files and load them into a DataFrame\n",
    "simulation_df_list = []\n",
    "for simulation_file in tqdm(list(Path(simulation_data_path).glob(\"*.json\"))):\n",
    "    with open(simulation_file, \"r\") as f:\n",
    "        # Load the simulation data into a DataFrame\n",
    "        cur_simulation_df = pd.DataFrame(json.load(f))\n",
    "\n",
    "        # Add the simulation file name as a column\n",
    "        cur_simulation_df[\"simulation_file\"] = simulation_file.name\n",
    "\n",
    "        # Strip the datetime from the file name, which looks like solved_boards_2023-12-05_01-01-26.json\n",
    "        cur_simulation_df[\"simulation_date_time_str\"] = datetime.datetime.strptime(\n",
    "            simulation_file.name, \"solved_boards_%Y-%m-%d_%H-%M-%S.json\"\n",
    "        ).strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "\n",
    "        # Edit the board_id to include the simulation_date_time_str (in string format)\n",
    "        cur_simulation_df[\"board_id\"] = cur_simulation_df.apply(\n",
    "            lambda row: f\"{row['board_id']}_{row['simulation_date_time_str']}\", axis=1\n",
    "        )\n",
    "\n",
    "        # Drop the simulation_date_time_str and simulation_file columns\n",
    "        cur_simulation_df.drop(\n",
    "            [\"simulation_date_time_str\", \"simulation_file\"], axis=1, inplace=True\n",
    "        )\n",
    "\n",
    "        # Add the simulation DataFrame to the list\n",
    "        simulation_df_list.append(cur_simulation_df)\n",
    "\n",
    "# Concatenate the simulation DataFrames into a single DataFrame\n",
    "simulation_df = pd.concat(simulation_df_list, ignore_index=True)\n",
    "\n",
    "# Add the length and points columns back\n",
    "simulation_df[\"length\"] = simulation_df[\"word\"].apply(len)\n",
    "simulation_df[\"points\"] = simulation_df[\"word\"].apply(score_boggle_word)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Collecting Statistics\n",
    "Now that I've simulated all of the Boggle boards and solved them, I want to collect some statistics about them. Here are things I'm interested in: \n",
    "\n",
    "- Frequency statistics for each word\n",
    "- Avg. total points available\n",
    "- Avg. total words available\n",
    "- Avg. # of 8+ length words\n",
    "\n",
    "I'll start by calculating the frequency stats for each word: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We're going to store the number of times each word was found in a board\n",
    "word_appearances_dict = {}\n",
    "\n",
    "# Iterate through each of the solved boards\n",
    "for board_idx, solved_board_df in tqdm(list(solved_boards_dict.items())):\n",
    "    # Extract the words from this board\n",
    "    words = solved_board_df[\"word\"].tolist()\n",
    "\n",
    "    # Iterate through each of the words and update the dictionary\n",
    "    for word in words:\n",
    "        word_appearances_dict[word] = word_appearances_dict.get(word, 0) + 1\n",
    "\n",
    "# Create a DataFrame from the dictionary\n",
    "word_appearances_df = pd.DataFrame.from_records(\n",
    "    [\n",
    "        {\"word\": word, \"appearances\": appearances, \"length\": len(word)}\n",
    "        for word, appearances in word_appearances_dict.items()\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Sort the DataFrame by the number of appearances\n",
    "word_appearances_df = word_appearances_df.sort_values(\n",
    "    by=[\"appearances\", \"length\", \"word\"], ascending=[False, True, True]\n",
    ")\n",
    "\n",
    "# Add a column indicating the likelihood of each word appearing\n",
    "word_appearances_df[\"prob_of_appearance\"] = (\n",
    "    word_appearances_df[\"appearances\"] / n_boards_to_simulate\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What are some of the most common words? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show the first 10 words, sorted by the number of appearances\n",
    "word_appearances_df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How about the least common words?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show the last 10 words, sorted by the number of appearances\n",
    "word_appearances_df.tail(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now: I want to determine some stats about the point distributions associated with each of the boards:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We're going to store each of the boards' stats in a list\n",
    "board_stats_df_records = []\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_board_stats(solved_board_df):\n",
    "    \"\"\"\n",
    "    This is a helper method to extract the stats from a solved board.\n",
    "    \"\"\"\n",
    "\n",
    "    # Calculate some stats about the current board\n",
    "    total_points = solved_board_df[\"points\"].sum()\n",
    "    num_words = len(solved_board_df)\n",
    "    eleven_pointers = len(solved_board_df.query(\"length >= 8\"))\n",
    "\n",
    "    # Return a dictionary containing the stats\n",
    "    return {\n",
    "        \"board_idx\": board_idx,\n",
    "        \"total_points\": total_points,\n",
    "        \"num_words\": num_words,\n",
    "        \"eleven_pointers\": eleven_pointers,\n",
    "    }\n",
    "\n",
    "\n",
    "# We're going to store each of the boards' stats in a list\n",
    "board_stats_df_records = []\n",
    "\n",
    "# Parallelize the board stats extraction\n",
    "futures = {}\n",
    "with ThreadPoolExecutor(max_workers=32) as executor:\n",
    "    for board_idx, solved_board_df in tqdm(list(solved_boards_dict.items())):\n",
    "        futures[board_idx] = executor.submit(extract_board_stats, solved_board_df)\n",
    "\n",
    "    for board_idx, future in tqdm(list(futures.items())):\n",
    "        board_stats_df_records.append(future.result())\n",
    "\n",
    "# Finally, make a DataFrame from the records\n",
    "board_stats_df = pd.DataFrame.from_records(board_stats_df_records)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
