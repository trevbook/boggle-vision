{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Motivation\n",
    "I want to try my hand at training a CNN for letter recognition sometime soon. In order to do that, I'm going to need to collect some training data. \n",
    "\n",
    "This notebook will parse through all of the labeled images I have, extract the processed tile images, and then save them as separate images. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup\n",
    "The cells below will set up the rest of this notebook. \n",
    "\n",
    "I'll start by configuring the kernel: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d:\\data\\programming\\boggle-vision\n"
     ]
    }
   ],
   "source": [
    "# Change directories to the root of the project\n",
    "%cd ..\n",
    "\n",
    "# Enable autoreload of modules\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, I'm going to import some relevant libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import statements\n",
    "import cv2\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import math\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "from statistics import mode\n",
    "import utils\n",
    "import cv2\n",
    "import pytesseract\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "import shutil\n",
    "\n",
    "# Importing custom modules\n",
    "import utils.board_detection as board_detect"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, I'm going to create a folder in the `data/` folder - this is where I'll store all of the data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Declare the path to the training-data folder\n",
    "training_data_path = Path(\"data/training-data\")\n",
    "original_data_path = Path(\"data/original-training-data\")\n",
    "\n",
    "# If it already exists, delete it (even if it's not empty)\n",
    "if training_data_path.exists():\n",
    "    shutil.rmtree(training_data_path)\n",
    "    \n",
    "if original_data_path.exists():\n",
    "    shutil.rmtree(original_data_path)\n",
    "\n",
    "# Create the training-data folder\n",
    "training_data_path.mkdir(parents=True, exist_ok=True)\n",
    "original_data_path.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading Data\n",
    "Here, I'm going to load in all of the pictures, as well as some information about each of them. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open the .csv file containing the labeled boards\n",
    "board_data_df = pd.read_csv(\"data/labeled-boards.csv\")\n",
    "\n",
    "# Add a column which is the parsed letter sequence\n",
    "board_data_df[\"parsed_letter_sequence\"] = board_data_df[\"letter_sequence\"].apply(\n",
    "    lambda letter_list: letter_list.split(\";\")\n",
    ")\n",
    "\n",
    "# Load all of the images using cv2\n",
    "file_path_to_image = {}\n",
    "for row in board_data_df.itertuples():\n",
    "    file_path_to_image[row.file_path] = cv2.imread(row.file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parsing Boards\n",
    "Below, I'm going to run each of the boards through a \"parsing\" method. This will extract the \"processed\" letter images for each of the different tiles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30/30 [00:11<00:00,  2.72it/s]\n"
     ]
    }
   ],
   "source": [
    "# We'll collect some results about the board data here\n",
    "all_parsed_boards_df_records = []\n",
    "\n",
    "# Iterate through all of the rows in the board data\n",
    "for row in tqdm(list(board_data_df.query(\"difficulty == 'easy'\").itertuples())):\n",
    "    # Try and parse the board\n",
    "    error_msg = None\n",
    "    try:\n",
    "        letter_img_sequence = board_detect.parse_boggle_board(\n",
    "            file_path_to_image[row.file_path],\n",
    "            max_image_height=1200,\n",
    "            return_parsed_img_sequence=True\n",
    "        )\n",
    "\n",
    "    except Exception as e:\n",
    "        continue\n",
    "\n",
    "    # Add some information to the all_parsed_boards_df_records\n",
    "    all_parsed_boards_df_records.append(\n",
    "        {\n",
    "            \"file_path\": row.file_path,\n",
    "            \"letter_img_sequence\": letter_img_sequence,\n",
    "            \"error_msg\": error_msg,\n",
    "        }\n",
    "    )\n",
    "\n",
    "# Parse the results into a dataframe\n",
    "all_parsed_boards_df = pd.DataFrame(all_parsed_boards_df_records)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Associating Images with Letters\n",
    "Finally, I'm going to create a final DataFrame, where each row represents a single tile from a test image. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30/30 [00:00<00:00, 64.10it/s]\n"
     ]
    }
   ],
   "source": [
    "# We're going to store each row of the eventual DataFrame in this list \n",
    "parsed_letter_img_df_records = []\n",
    "\n",
    "# Iterate through each row in the parsed boards DataFrame\n",
    "for row in tqdm(list(all_parsed_boards_df.merge(board_data_df, on=\"file_path\").itertuples())):\n",
    "    \n",
    "    # Extract some information about the current board\n",
    "    cur_board_file_path = Path(row.file_path)\n",
    "    cur_board_letter_sequence = row.parsed_letter_sequence\n",
    "    cur_board_letter_img_sequence = row.letter_img_sequence\n",
    "    \n",
    "    # Iterate through each of the letters in the parsed letter sequence\n",
    "    for tile_idx, letter in enumerate(cur_board_letter_sequence):\n",
    "        \n",
    "        # Determine the image associated with the current tile_idx\n",
    "        cur_tile_img = cur_board_letter_img_sequence.get(tile_idx, None)\n",
    "        if cur_tile_img is None:\n",
    "            continue\n",
    "        \n",
    "        # Save the current tile image to the training-data directory\n",
    "        cur_tile_img_file_path = training_data_path / f\"{letter}_{cur_board_file_path.stem}_{tile_idx}.png\"\n",
    "        \n",
    "        # Save cur_tile_img to cur_tile_img_file_path. Do not use cv2.imwrite - it introduces compression artifacts\n",
    "        Image.fromarray(cur_tile_img).save(cur_tile_img_file_path)\n",
    "        \n",
    "        # Store the information about the current tile in the parsed_letter_img_df_records\n",
    "        parsed_letter_img_df_records.append(\n",
    "            {\n",
    "                \"board_img_file_path\": cur_board_file_path,\n",
    "                \"tile_idx\": tile_idx,\n",
    "                \"letter\": letter,\n",
    "                \"tile_img\": cur_tile_img,\n",
    "                \"tile_img_file_path\": cur_tile_img_file_path,\n",
    "            }\n",
    "        )\n",
    "\n",
    "# Now, make a DataFrame from the parsed_letter_img_df_records\n",
    "parsed_letter_img_df = pd.DataFrame(parsed_letter_img_df_records)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, with this DataFrame created, we're going to drop the images from it and then save it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the index (i.e., a list of all of the tile images) to an Excel file\n",
    "parsed_letter_img_df.drop(columns=[\"tile_img\"]).to_excel(\n",
    "    \"data/training-data-index.xlsx\", index=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're also going to save some stats; this will be a count of how many of each tile we have. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine the count of each tile in the dataset\n",
    "original_tile_count_df = (\n",
    "    parsed_letter_img_df.drop(columns=[\"tile_img\"])\n",
    "    .groupby(\"letter\")\n",
    "    .agg(count=(\"tile_idx\", \"count\"))\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "# Ensure that all of the tile types are represented\n",
    "from utils.settings import allowed_boggle_tiles\n",
    "\n",
    "# Create a DataFrame to store the tile counts\n",
    "tile_count_df_records = []\n",
    "for tile in allowed_boggle_tiles:\n",
    "    if tile not in original_tile_count_df[\"letter\"].values:\n",
    "        tile_count_df_records.append(\n",
    "            {\n",
    "                \"letter\": tile,\n",
    "                \"count\": 0,\n",
    "            }\n",
    "        )\n",
    "    else:\n",
    "        tile_count_df_records.append(\n",
    "            {\n",
    "                \"letter\": tile,\n",
    "                \"count\": original_tile_count_df.query(f\"letter == '{tile}'\")[\n",
    "                    \"count\"\n",
    "                ].values[0],\n",
    "            }\n",
    "        )\n",
    "tile_count_df = pd.DataFrame(tile_count_df_records)\n",
    "\n",
    "# Store the tile counts in an Excel file\n",
    "tile_count_df.sort_values(\"count\", ascending=False).to_excel(\n",
    "    \"data/training-data-stats.xlsx\", index=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we're going to copy this folder. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1080/1080 [00:02<00:00, 417.11it/s]\n"
     ]
    }
   ],
   "source": [
    "# Copy all of the images from the data/training-data folder to the data/original-training-data folder\n",
    "for file_path in tqdm(list(training_data_path.glob(\"*.png\"))):\n",
    "    shutil.copy(str(file_path), str(original_data_path / file_path.name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Augmenting Training Data\n",
    "In order to bolster the training data that I've got, I'm going to do a little duplication and rotation. \n",
    "\n",
    "First, I'll set up this process and parameterize it a little bit. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameterize the data augmentation process\n",
    "max_class_count_multiplier = 2\n",
    "n_per_rotation = 1\n",
    "\n",
    "# Create a DataFrame detailing the tile counts\n",
    "tile_img_df = parsed_letter_img_df[[\"tile_img_file_path\", \"tile_idx\", \"letter\", \"tile_img\"]].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, to start: I'm going to determine how many of each letter I need to create."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a DataFrame mapping the letter to the tile count\n",
    "letter_to_tile_ct_df = (\n",
    "    tile_img_df.groupby(\"letter\")\n",
    "    .agg(count=(\"tile_idx\", \"count\"))\n",
    "    .reset_index()\n",
    "    .sort_values(\"count\", ascending=False)\n",
    ")\n",
    "\n",
    "# Determine the number of tiles in the largest class\n",
    "max_class_count = letter_to_tile_ct_df[\"count\"].max()\n",
    "\n",
    "# Determine how many samples each class ought to have \n",
    "samples_per_class = math.ceil(max_class_count * max_class_count_multiplier)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, I'm going to iterate through each of the existing letter images, and determine how many times I need to save them. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# As we duplicate images, we're going to keep track of them in this list\n",
    "duplicated_letter_img_df_records = []\n",
    "\n",
    "# We're going to keep track of how many times we've duplicated each image\n",
    "image_duplicate_ct_dict = {}\n",
    "\n",
    "# Iterate through each of the letters and determine how many times they need to be duplicated\n",
    "for row in letter_to_tile_ct_df.itertuples():\n",
    "    \n",
    "    # Determine the letter and the number of times it needs to be duplicated\n",
    "    cur_letter = row.letter\n",
    "    cur_letter_count = row.count\n",
    "    n_times_to_duplicate = samples_per_class - cur_letter_count\n",
    "    \n",
    "    # Subset the tile_img_df to only include the current letter\n",
    "    cur_letter_tile_img_df = tile_img_df.query(\"letter == @cur_letter\").copy()\n",
    "    \n",
    "    # For each of the times to duplicate, duplicate the letter\n",
    "    for duplicate_idx in range(n_times_to_duplicate):\n",
    "        \n",
    "        # Determine which letter we're going to copy \n",
    "        letter_to_copy_idx = duplicate_idx % cur_letter_count\n",
    "        df_row_to_copy = cur_letter_tile_img_df.iloc[letter_to_copy_idx]\n",
    "        \n",
    "        # Now, we're going to create a new filepath for the duplicated image \n",
    "        cur_letter_file_path = Path(df_row_to_copy.tile_img_file_path)\n",
    "        cur_letter_file_stem = cur_letter_file_path.stem\n",
    "        duplicate_ct_for_cur_img = image_duplicate_ct_dict.get(cur_letter_file_stem, 0)\n",
    "        duplicate_file_path = f\"{cur_letter_file_stem}_copy-{(duplicate_ct_for_cur_img+1):04}.png\"\n",
    "        duplicate_file_path = cur_letter_file_path.parent / duplicate_file_path\n",
    "        \n",
    "        # Make sure to store the fact that we've duplicated this image\n",
    "        image_duplicate_ct_dict[cur_letter_file_stem] = duplicate_ct_for_cur_img + 1\n",
    "        \n",
    "        # Now, we'll add a record to the duplicated_letter_img_df_records\n",
    "        duplicated_letter_img_df_records.append({\n",
    "            \"tile_img_file_path\": duplicate_file_path,\n",
    "            \"tile_idx\": df_row_to_copy.tile_idx,\n",
    "            \"letter\": df_row_to_copy.letter,\n",
    "            \"tile_img\": df_row_to_copy.tile_img,\n",
    "        })\n",
    "\n",
    "# Now: we're going to create a Dataframe out of the duplicated_letter_img_df_records\n",
    "duplicated_letter_img_df = pd.DataFrame.from_records(duplicated_letter_img_df_records)\n",
    "\n",
    "# Create a DataFrame containing all of the letter images\n",
    "all_letter_img_df = pd.concat([\n",
    "    tile_img_df,\n",
    "    duplicated_letter_img_df,\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we've created this DataFrame, we'll need to save all of the files. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7304/7304 [00:03<00:00, 2283.75it/s]\n"
     ]
    }
   ],
   "source": [
    "# Iterate through each of the rows in the duplicated_letter_img_df and save the images\n",
    "for row in tqdm(list(duplicated_letter_img_df.itertuples())):\n",
    "    Image.fromarray(row.tile_img).save(str(row.tile_img_file_path))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that this is done: we need to rotate all of the pictures. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We're going to keep track of the images to save in a DataFrame\n",
    "rotated_tile_img_df_records = []\n",
    "\n",
    "# Iterate through each of the rotations that we want to do \n",
    "for cur_rotation_idx in range(n_per_rotation):\n",
    "    \n",
    "    # Iterate through each of the tiles in the dataset\n",
    "    for row in all_letter_img_df.itertuples():\n",
    "        \n",
    "        # Iterate through each of the rotation angles\n",
    "        for cur_rotation_angle in [0, 90, 180, 270]:\n",
    "            \n",
    "            # Determine the new file path for the rotated image\n",
    "            cur_file_path = Path(row.tile_img_file_path)\n",
    "            cur_file_stem = cur_file_path.stem\n",
    "            rotated_file_path = cur_file_path.parent / f\"{cur_file_stem}_rotate_{cur_rotation_idx:02}-{cur_rotation_angle:03}.png\"\n",
    "            \n",
    "            # Rotate the image \n",
    "            img = row.tile_img\n",
    "            image_pil = Image.fromarray(np.uint8(img))\n",
    "            rotated_img = image_pil.rotate(cur_rotation_angle)\n",
    "            rotated_img = np.array(rotated_img)\n",
    "            \n",
    "            \n",
    "            # Add a record to the rotated_tile_img_df_records\n",
    "            rotated_tile_img_df_records.append({\n",
    "                \"tile_img_file_path\": rotated_file_path,\n",
    "                \"tile_idx\": row.tile_idx,\n",
    "                \"letter\": row.letter,\n",
    "                \"tile_img\": rotated_img,\n",
    "            })\n",
    "\n",
    "# Finally, we're going to create a DataFrame out of the rotated_tile_img_df_records\n",
    "rotated_tile_img_df = pd.DataFrame.from_records(rotated_tile_img_df_records)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we're going to save all of the rotated tiles. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 33536/33536 [00:14<00:00, 2255.60it/s]\n"
     ]
    }
   ],
   "source": [
    "# Iterate through each of the rows in the rotated_tile_img_df and save the images\n",
    "for row in tqdm(list(rotated_tile_img_df.itertuples())):\n",
    "    Image.fromarray(row.tile_img).save(str(row.tile_img_file_path))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
