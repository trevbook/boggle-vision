{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Motivation\n",
    "In the previous notebook (**`01. Detecting a Boggle Board`**), I familiarized myself with a couple of the tactics I could use to process pictures of Boggle boards. In this notebook, I want to refine that technique, and try to make it a little more foolproof. \n",
    "\n",
    "Here's a general overview of my strategy: \n",
    "\n",
    "1. Apply Contour Detection to identify the Boggle Board ([tutorial here](https://learnopencv.com/contour-detection-using-opencv-python-c/))\n",
    "2. Warp the perspective of the board to achieve a more top-down view\n",
    "3. Apply contour detection *again*, and then try and use the contour hierarchies to identify the letters within the Boggle board \n",
    "4. Try and refine the extraction of the letters, cleaning them up \n",
    "5. Apply OCR on each of the letters\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup\n",
    "The cells below will set up the rest of this notebook. \n",
    "\n",
    "First, I'll configure the kernel: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d:\\data\\programming\\boggle-vision\n"
     ]
    }
   ],
   "source": [
    "# Change directories to the root of the project\n",
    "%cd ..\n",
    "\n",
    "# Enable autoreload of modules\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, I'll import some relevant libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'settings'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32md:\\data\\programming\\boggle-vision\\notebooks\\02. Better Board Detection.ipynb Cell 5\u001b[0m line \u001b[0;36m9\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/data/programming/boggle-vision/notebooks/02.%20Better%20Board%20Detection.ipynb#W4sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mnumpy\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mnp\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/data/programming/boggle-vision/notebooks/02.%20Better%20Board%20Detection.ipynb#W4sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mstatistics\u001b[39;00m \u001b[39mimport\u001b[39;00m mode\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/data/programming/boggle-vision/notebooks/02.%20Better%20Board%20Detection.ipynb#W4sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mutils\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmisc\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mold_utils\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/data/programming/boggle-vision/notebooks/02.%20Better%20Board%20Detection.ipynb#W4sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mcv2\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/data/programming/boggle-vision/notebooks/02.%20Better%20Board%20Detection.ipynb#W4sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mpytesseract\u001b[39;00m\n",
      "File \u001b[1;32md:\\data\\programming\\boggle-vision\\utils\\misc.py:20\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39measyocr\u001b[39;00m\n\u001b[0;32m     19\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtraceback\u001b[39;00m\n\u001b[1;32m---> 20\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39msettings\u001b[39;00m\n\u001b[0;32m     22\u001b[0m \u001b[39m# Indicate which tiles are allowed in Boggle\u001b[39;00m\n\u001b[0;32m     23\u001b[0m allowed_boggle_tiles \u001b[39m=\u001b[39m [\n\u001b[0;32m     24\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mA\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m     25\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mB\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     54\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mHe\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m     55\u001b[0m ]\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'settings'"
     ]
    }
   ],
   "source": [
    "# Import statements\n",
    "import cv2\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import math\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "from statistics import mode\n",
    "import utils.misc as old_utils\n",
    "import cv2\n",
    "import pytesseract\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "from concurrent.futures import ThreadPoolExecutor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Methods\n",
    "As I define methods to be used throughout the notebook, I'll move them up here. \n",
    "\n",
    "This first one will resize an image to a particular scale. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resize_image(desired_height, image):\n",
    "    \"\"\"\n",
    "    This function resizes an image to a desired height while maintaining the aspect ratio.\n",
    "    \"\"\"\n",
    "\n",
    "    # Resize image\n",
    "    height, width = image.shape[:2]\n",
    "    aspect_ratio = width / height\n",
    "    desired_width = int(desired_height * aspect_ratio)\n",
    "    return cv2.resize(\n",
    "        image, (desired_width, desired_height), interpolation=cv2.INTER_AREA\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading Data\n",
    "First, I'm going to load in all of the different pictures. I'll put them into a DataFrame; that way, I can more easily test the process across all of them at once. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_height_for_pic = 2000\n",
    "\n",
    "# Iterate through the test-pictures folder\n",
    "pictures_df_records = []\n",
    "for child_file in Path(\"data/test-pictures/\").iterdir():\n",
    "    # If the child_file is a .png file, then we want to process it\n",
    "    if child_file.suffix == \".png\":\n",
    "        # Only add the file if it's prefixed with \"easy\", \"medium\", or \"hard\"\n",
    "        if (\n",
    "            child_file.name.startswith(\"easy\")\n",
    "            or child_file.name.startswith(\"medium\")\n",
    "            or child_file.name.startswith(\"hard\")\n",
    "        ):\n",
    "            pictures_df_records.append(\n",
    "                {\n",
    "                    \"file_name\": child_file.stem,\n",
    "                    \"file_path\": str(child_file),\n",
    "                    \"image\": resize_image(max_height_for_pic, cv2.imread(str(child_file))),\n",
    "                    \"number\": int(child_file.stem.split(\"-\")[-1]),\n",
    "                    \"difficulty\": child_file.stem.split(\"-\")[0],\n",
    "                }\n",
    "            )\n",
    "\n",
    "# Create a DataFrame from the records\n",
    "pictures_df = pd.DataFrame(pictures_df_records)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Board Detection Process\n",
    "Below, I'm going to run through the board detecgtion process. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Step 0:** Parameterizing the Detection Process\n",
    "There are a couple of general settings I want to declare for the board detection process - I'll declare those here. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Indicating a test image to use (one that's easy)\n",
    "input_image = pictures_df.query(\"difficulty == 'easy'\").iloc[1].image\n",
    "\n",
    "# Indicating the pixel brightness threshold for the binary thresholding\n",
    "binary_threshold = 100\n",
    "\n",
    "# Determine how many contours to check in the initial contour detection\n",
    "initial_contour_detection_n_to_process = 15\n",
    "\n",
    "# Indicate the maximum amount of children contours for a contour to be considered a board\n",
    "max_children_contours = 80\n",
    "\n",
    "# Indicate the maximum amount of the picture that a board can take up\n",
    "board_max_area = 0.7\n",
    "board_min_area = 0.15\n",
    "\n",
    "# Indicate the amount that we'll be deflating the board contour by\n",
    "board_contour_expansion_amount = 15"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Step 1:** Contour Detection for Locating the Board\n",
    "The first step we'll do: try and run through some contour detection for finding the board. \n",
    "\n",
    "Essentially, we're going to look for a \"mostly-squareish\", large contour. This is hopefully the board. I'll start by running contour detection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine the area of the input image (this is for later)\n",
    "entire_image_area = input_image.shape[0] * input_image.shape[1]\n",
    "\n",
    "# Start by converting the image to greyscale\n",
    "gray_image = cv2.cvtColor(input_image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# Apply some binary thresholding to the greyscale image\n",
    "ret, thresholded_image = cv2.threshold(\n",
    "    gray_image, binary_threshold, 255, cv2.THRESH_BINARY\n",
    ")\n",
    "\n",
    "# Detect the contours on the thresholded image\n",
    "contours, hierarchy = cv2.findContours(\n",
    "    thresholded_image, cv2.RETR_TREE, cv2.CHAIN_APPROX_NONE\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now I'm going to want to iterate through the hiearchy to determine which contours are actually the board. \n",
    "\n",
    "**NOTE:** This is a fairly difficult problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the contours that have the most immediate children\n",
    "repeated_parents_list = [\n",
    "    contour_navlist[-1] for contour_navlist in hierarchy[0] if contour_navlist[-1] != -1\n",
    "]\n",
    "most_common_parents = list(\n",
    "    pd.DataFrame(repeated_parents_list)\n",
    "    .value_counts()\n",
    "    .head(initial_contour_detection_n_to_process)\n",
    "    .reset_index()[0]\n",
    ")\n",
    "\n",
    "# Retreive the contours that have the most immediate children\n",
    "most_common_parent_contours = [contours[i] for i in most_common_parents]\n",
    "\n",
    "# Iterate through each of the contours to find square-ish shapes\n",
    "# https://chat.openai.com/share/5b096067-aa3c-4632-804e-2b9cfa719933\n",
    "# TODO: This is definitely a bit hacky; I should come back to this\n",
    "board_contour = None\n",
    "square_ish_contours = []\n",
    "for i, cur_contour in enumerate(most_common_parent_contours):\n",
    "    # Approximate teh contour to a polygon\n",
    "    epsilon = 0.05 * cv2.arcLength(cur_contour, True)\n",
    "    polygon = cv2.approxPolyDP(cur_contour, epsilon, True)\n",
    "\n",
    "    # If the polygon has 4 points, then we can assume we have found the board\n",
    "    if len(polygon) == 4:\n",
    "        square_ish_contours.append(polygon)\n",
    "\n",
    "# Now, iterate through the square-ish contours and find the one that is the largest\n",
    "largest_contour_area = 0\n",
    "for cur_contour in square_ish_contours:\n",
    "    \n",
    "    # If the current contour's area is larger than the largest contour's area, then\n",
    "    # we'll set the largest contour to the current contour\n",
    "    cur_contour_area = cv2.contourArea(cur_contour)\n",
    "    if cur_contour_area > largest_contour_area and cur_contour_area <= (entire_image_area * board_max_area) and cur_contour_area >= (entire_image_area * board_min_area):\n",
    "        largest_contour_area = cur_contour_area\n",
    "        board_contour = cur_contour\n",
    "\n",
    "# If the board contour is still None, then we didn't find a board\n",
    "if board_contour is None:\n",
    "    print(\"No board was found.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next: I'm going to slightly \"expand\" the contour that I've found. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Learn about this method more, since I'd copied it from ChatGPT 😂\n",
    "\n",
    "\n",
    "def expand_contour(contour, dilation_size=5):\n",
    "    # Create an empty mask to draw the contour onto\n",
    "    mask = np.zeros(input_image.shape[:2], dtype=np.uint8)\n",
    "\n",
    "    # Draw the contour onto the mask (using a thickness of -1 to fill the contour)\n",
    "    cv2.drawContours(mask, [contour], -1, (255), thickness=-1)\n",
    "\n",
    "    # Create a structuring element for the dilation\n",
    "    kernel = np.ones((dilation_size, dilation_size), np.uint8)\n",
    "\n",
    "    # Dilate the mask\n",
    "    dilated_mask = cv2.dilate(mask, kernel, iterations=1)\n",
    "\n",
    "    # Find the contours of the dilated mask\n",
    "    dilated_contours, _ = cv2.findContours(\n",
    "        dilated_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE\n",
    "    )\n",
    "\n",
    "    # The dilated contour will be the one with the largest area\n",
    "    dilated_contour = max(dilated_contours, key=cv2.contourArea)\n",
    "\n",
    "    # Simplify the dilated contour\n",
    "    dilated_contour = cv2.approxPolyDP(\n",
    "        dilated_contour, 0.02 * cv2.arcLength(dilated_contour, True), True,\n",
    "    )\n",
    "\n",
    "    return dilated_contour"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now - if `board_contour` is not `None` at this stage, then we've supposedly found our board. I'll display it below: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if board_contour is None:\n",
    "    final_board_contour = None\n",
    "    print(f\"FAILED TO FIND THE BOARD!\")\n",
    "    image_copy = input_image.copy()\n",
    "    plt.imshow(\n",
    "        cv2.drawContours(\n",
    "            image_copy,\n",
    "            # contours=[polygon],\n",
    "            contours=contours,\n",
    "            contourIdx=-1,\n",
    "            color=(0, 255, 0),\n",
    "            thickness=4,\n",
    "        )\n",
    "    )\n",
    "    plt.imshow(image_copy, cmap=\"gray\")\n",
    "    plt.show()\n",
    "else:\n",
    "    # Add the expansion of the board contour\n",
    "    expanded_contour = expand_contour(board_contour, 12)\n",
    "\n",
    "    # Find the minimum area rectangle\n",
    "    min_rect = cv2.minAreaRect(expanded_contour)\n",
    "\n",
    "    # Calculate the box points\n",
    "    box_points = cv2.boxPoints(min_rect)\n",
    "\n",
    "    # Convert box_points to an integer array (necessary for drawing the contour)\n",
    "    box_points = np.int0(box_points)\n",
    "\n",
    "    # Create a new contour from the box points\n",
    "    bounding_rect_contour = box_points.reshape((-1, 1, 2))\n",
    "    final_board_contour = bounding_rect_contour\n",
    "\n",
    "    # Draw this final contour\n",
    "    image_copy = input_image.copy()\n",
    "    image_copy = cv2.drawContours(\n",
    "        image_copy,\n",
    "        # contours=[polygon],\n",
    "        contours=[final_board_contour],\n",
    "        contourIdx=-1,\n",
    "        color=(0, 255, 0),\n",
    "        thickness=4,\n",
    "    )\n",
    "    plt.imshow(cv2.cvtColor(image_copy, cv2.COLOR_BGR2RGB), cmap=\"gray\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Step 2:** Warping Perspective to Top-Down\n",
    "At this point, I've hopefully found the board. Now, I need to warp the perspective of the image to be centered around the board."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def warp_perspective_to_top_down(img, contour):\n",
    "    \"\"\"\n",
    "    This method will take an image and a contour and warp the image to a top-down view. \n",
    "    The method will return the warped image.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Determine the corner points of the board\n",
    "    corner_points = [contour_corner[0].tolist() for contour_corner in contour]\n",
    "\n",
    "    # Unpack the corner points\n",
    "    pt_A, pt_B, pt_C, pt_D = corner_points\n",
    "\n",
    "    # Use the L2 norm to calculate the width and height of the new image\n",
    "    width_AD = np.sqrt(((pt_A[0] - pt_D[0]) ** 2) + ((pt_A[1] - pt_D[1]) ** 2))\n",
    "    width_BC = np.sqrt(((pt_B[0] - pt_C[0]) ** 2) + ((pt_B[1] - pt_C[1]) ** 2))\n",
    "    maxWidth = max(int(width_AD), int(width_BC))\n",
    "    height_AB = np.sqrt(((pt_A[0] - pt_B[0]) ** 2) + ((pt_A[1] - pt_B[1]) ** 2))\n",
    "    height_CD = np.sqrt(((pt_C[0] - pt_D[0]) ** 2) + ((pt_C[1] - pt_D[1]) ** 2))\n",
    "    maxHeight = max(int(height_AB), int(height_CD))\n",
    "\n",
    "    # Compute the perspective transform matrix\n",
    "    input_pts = np.float32([pt_A, pt_B, pt_C, pt_D])\n",
    "    output_pts = np.float32(\n",
    "        [[0, 0], [0, maxHeight - 1], [maxWidth - 1, maxHeight - 1], [maxWidth - 1, 0]]\n",
    "    )\n",
    "    M = cv2.getPerspectiveTransform(input_pts, output_pts)\n",
    "\n",
    "    warped_image = cv2.warpPerspective(\n",
    "        img, M, (maxWidth, maxHeight), flags=cv2.INTER_LINEAR\n",
    "    )\n",
    "    \n",
    "    # Flip the image horizontally and return it \n",
    "    return cv2.flip(warped_image, 0)\n",
    "\n",
    "# We're only going to run the perspective transform if there are 4 corners\n",
    "if final_board_contour is not None and len(final_board_contour) == 4: \n",
    "    \n",
    "    # Warp the image to a top-down view\n",
    "    board_image = warp_perspective_to_top_down(input_image, final_board_contour)\n",
    "    \n",
    "    # Display the image using matplotlib\n",
    "    plt.imshow(cv2.cvtColor(board_image, cv2.COLOR_BGR2RGB))\n",
    "    plt.show()\n",
    "\n",
    "# If there aren't 4 corners, we'll just use the original image\n",
    "else:\n",
    "    print(f\"THE CONTOUR DOESN'T HAVE 4 CORNERS!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Step 3:** Tile/Letter Contour Detection\n",
    "Now, I need to run contour detection again - this time on the newly extracted `board_image`. \n",
    "\n",
    "My idea here: I want to try and detect contours that have roughly the same size. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start by converting the image to greyscale\n",
    "gray_board_image = cv2.cvtColor(board_image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# # Apply Gaussian blur to the greyscale image\n",
    "# blurred_board_image = cv2.GaussianBlur(gray_board_image, (15, 15), 0)\n",
    "\n",
    "# # Apply some binary thresholding to the greyscale image\n",
    "# thresholded_board_image = cv2.adaptiveThreshold(\n",
    "#     blurred_board_image, 200, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY, 21, 5\n",
    "# )\n",
    "\n",
    "ret, thresholded_board_image = cv2.threshold(\n",
    "    gray_board_image, binary_threshold, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "# Detect the contours on the thresholded image\n",
    "contours, hierarchy = cv2.findContours(\n",
    "    thresholded_board_image, cv2.RETR_TREE, cv2.CHAIN_APPROX_NONE\n",
    ")\n",
    "\n",
    "board_image_copy = board_image.copy()\n",
    "board_image_copy = cv2.drawContours(\n",
    "    board_image_copy,\n",
    "    # contours=[polygon],\n",
    "    contours=contours,\n",
    "    contourIdx=-1,\n",
    "    color=(0, 255, 0),\n",
    "    thickness=2,\n",
    ")\n",
    "plt.imshow(cv2.cvtColor(board_image_copy, cv2.COLOR_BGR2RGB), cmap=\"gray\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the total area of the image\n",
    "board_image_area = board_image.shape[0] * board_image.shape[1]\n",
    "\n",
    "contour_df = pd.DataFrame(\n",
    "    [\n",
    "        {\n",
    "            \"idx\": idx,\n",
    "            \"area\": cv2.contourArea(contour),\n",
    "        }\n",
    "        for idx, contour in enumerate(contours)\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Filter out some noise from the contour DataFrame\n",
    "noise_filtered_contour_df = contour_df.query(\"area > 0\").sort_values(\n",
    "    \"area\", ascending=False\n",
    ")\n",
    "\n",
    "# Add a column indicating the difference in size between each contour\n",
    "difference = []\n",
    "difference_pct = []\n",
    "prev_row_area = noise_filtered_contour_df.iloc[0].area * 2\n",
    "for idx, row in noise_filtered_contour_df.iterrows():\n",
    "    difference.append(prev_row_area - row.area)\n",
    "    difference_pct.append((prev_row_area - row.area) / prev_row_area)\n",
    "    prev_row_area = row.area\n",
    "noise_filtered_contour_df[\"difference\"] = difference\n",
    "noise_filtered_contour_df[\"difference_pct\"] = difference_pct\n",
    "noise_filtered_contour_df = noise_filtered_contour_df.reset_index(drop=True)\n",
    "\n",
    "noise_filtered_contour_df[\"pct_of_image\"] = noise_filtered_contour_df.area / board_image_area\n",
    "\n",
    "noise_filtered_contour_df = noise_filtered_contour_df.query(\"pct_of_image < 0.02\")\n",
    "\n",
    "# Iterate through each contour and try and locate the tiles\n",
    "size_difference_threshold = 0.4\n",
    "tile_contour_idxs = []\n",
    "prev_row = noise_filtered_contour_df.iloc[0]\n",
    "for idx, row in enumerate(list(noise_filtered_contour_df.itertuples())):\n",
    "    if idx == 0:\n",
    "        continue\n",
    "    if row.difference_pct <= size_difference_threshold:\n",
    "        tile_contour_idxs.append(prev_row.idx)\n",
    "        tile_contour_idxs.append(row.idx)\n",
    "    elif row.difference_pct > size_difference_threshold and len(tile_contour_idxs) > 0:\n",
    "        break\n",
    "    prev_row = row\n",
    "tile_contour_idxs = list(set(tile_contour_idxs))\n",
    "\n",
    "# Now, get the bounding boxes for each tile\n",
    "tile_contours = [contours[int(idx)] for idx in tile_contour_idxs]\n",
    "\n",
    "board_image_copy = board_image.copy()\n",
    "board_image_copy = cv2.drawContours(\n",
    "    board_image_copy,\n",
    "    # contours=[polygon],\n",
    "    contours=tile_contours,\n",
    "    contourIdx=-1,\n",
    "    color=(0, 255, 0),\n",
    "    thickness=3,\n",
    ")\n",
    "plt.imshow(cv2.cvtColor(board_image_copy, cv2.COLOR_BGR2RGB), cmap=\"gray\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Step 4:** Cleaning Tile Images\n",
    "Next, I need to clean up the images of the tiles that we've extracted. \n",
    "\n",
    "I've got contours for each the tiles. I want to approximate polygons for each of them, and then create new images from each of them. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We're going to store the square-ified contours in this list\n",
    "square_tile_contours = []\n",
    "# Iterate through each of the tile contours\n",
    "for tile_contour in tile_contours:\n",
    "    # Find the minimum area rectangle\n",
    "    min_rect = cv2.minAreaRect(tile_contour)\n",
    "\n",
    "    # Calculate the box points\n",
    "    box_points = cv2.boxPoints(min_rect)\n",
    "\n",
    "    # Convert box_points to an integer array (necessary for drawing the contour)\n",
    "    box_points = np.int0(box_points)\n",
    "\n",
    "    # Create a new contour from the box points\n",
    "    square_tile_contours.append(box_points.reshape((-1, 1, 2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the square contours created, we're going to warp the perspectives so that we're showing all of the letters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "board_tile_df_records = []\n",
    "tile_idx_to_image = {}\n",
    "for idx, square_tile_contour in enumerate(square_tile_contours):\n",
    "    cur_tile_centroid = np.mean(square_tile_contour, axis=0)[0]\n",
    "    board_tile_df_records.append(\n",
    "        {\n",
    "            \"contour\": square_tile_contour,\n",
    "            \"tile_idx\": idx,\n",
    "            \"centroid_x\": cur_tile_centroid[0],\n",
    "            \"centroid_y\": cur_tile_centroid[1],\n",
    "        }\n",
    "    )\n",
    "    tile_idx_to_image[idx] = warp_perspective_to_top_down(\n",
    "        board_image, square_tile_contour\n",
    "    )\n",
    "board_tile_df = pd.DataFrame(board_tile_df_records).sort_values(\n",
    "    [\"centroid_y\", \"centroid_x\"], ascending=[True, True]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we're going to edit the board tile images to only show the child contours. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We're going to collect each of the images in this dictionary\n",
    "tile_idx_to_letter_image = {}\n",
    "\n",
    "# Iterate over each tile image\n",
    "for idx, cur_tile_row in enumerate(list(board_tile_df.itertuples())):\n",
    "    cur_tile_image = tile_idx_to_image[cur_tile_row.tile_idx]\n",
    "\n",
    "    # Get the area of the cur_tile_image\n",
    "    cur_tile_image_area = cur_tile_image.shape[0] * cur_tile_image.shape[1]\n",
    "\n",
    "    # Apply contour detection on the image\n",
    "    grey_tile_image = cv2.cvtColor(cur_tile_image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Apply some Gaussian blurring to the greyscale image\n",
    "    blurred_tile_image = cv2.GaussianBlur(grey_tile_image, (7, 7), 0)\n",
    "\n",
    "    # # Apply some binary thresholding to the greyscale image\n",
    "    thresholded_tile_image = cv2.adaptiveThreshold(\n",
    "        blurred_tile_image,\n",
    "        200,\n",
    "        cv2.ADAPTIVE_THRESH_GAUSSIAN_C,\n",
    "        cv2.THRESH_BINARY,\n",
    "        41,\n",
    "        5,\n",
    "    )\n",
    "\n",
    "    contours, hierarchy = cv2.findContours(\n",
    "        thresholded_tile_image, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE\n",
    "    )\n",
    "    hierarchy_df = old_utils.hierarchy_to_dataframe(hierarchy)\n",
    "\n",
    "    # Calculate the areas of each contour and add it to the dataframe\n",
    "    contour_areas = [cv2.contourArea(c) for c in contours]\n",
    "    hierarchy_df[\"contour_area\"] = contour_areas\n",
    "    hierarchy_df[\"pct_of_total_area\"] = (\n",
    "        hierarchy_df[\"contour_area\"] / cur_tile_image_area\n",
    "    )\n",
    "\n",
    "    # Figure out the midpoint of each contour\n",
    "    hierarchy_df[\"contour_midpoint\"] = hierarchy_df.apply(\n",
    "        lambda x: np.mean(contours[x.contour_idx], axis=0)[0], axis=1\n",
    "    )\n",
    "    hierarchy_df[\"contour_midpoint_x\"] = hierarchy_df[\"contour_midpoint\"].apply(\n",
    "        lambda x: x[0]\n",
    "    )\n",
    "    hierarchy_df[\"contour_midpoint_y\"] = hierarchy_df[\"contour_midpoint\"].apply(\n",
    "        lambda x: x[1]\n",
    "    )\n",
    "    hierarchy_df = hierarchy_df.drop(columns=[\"contour_midpoint\"])\n",
    "\n",
    "    original_hierarchy_df = hierarchy_df.copy()\n",
    "\n",
    "    underline_contours = old_utils.identify_underline_contours(\n",
    "        thresholded_tile_image, hierarchy_df\n",
    "    )\n",
    "\n",
    "    # Filter out level-1 contours that are too small\n",
    "    hierarchy_df = pd.concat(\n",
    "        [\n",
    "            hierarchy_df.query(\"hierarchy_level != 1\"),\n",
    "            hierarchy_df.query(\"hierarchy_level == 1 and pct_of_total_area >= 0.03\"),\n",
    "            original_hierarchy_df[\n",
    "                original_hierarchy_df[\"contour_idx\"].isin(underline_contours)\n",
    "            ],\n",
    "        ]\n",
    "    ).drop_duplicates(subset=[\"contour_idx\"])\n",
    "\n",
    "    # We're going to check if the largest level 1 contour is a rectangle.\n",
    "    largest_level_1_contour_idx = (\n",
    "        hierarchy_df.query(\"hierarchy_level==1\")\n",
    "        .sort_values(\"contour_area\", ascending=False)\n",
    "        .head(1)\n",
    "        .iloc[0]\n",
    "        .contour_idx\n",
    "    )\n",
    "    largest_level_1_contour = contours[largest_level_1_contour_idx]\n",
    "    epsilon = 0.025 * cv2.arcLength(largest_level_1_contour, True)\n",
    "    poly_approx = cv2.approxPolyDP(largest_level_1_contour, epsilon, True)\n",
    "\n",
    "    # If the approximated polygon is a rectangle, then this tile is either \"I\" or\n",
    "    # the blank tile. We'll remove any level 2 contours.\n",
    "    if len(poly_approx) == 4:\n",
    "        hierarchy_df = hierarchy_df.query(\"hierarchy_level != 2\")\n",
    "\n",
    "    # Find the largest contour that's not the outermost contour\n",
    "    level_1_contours = [\n",
    "        contours[idx]\n",
    "        for idx in list(\n",
    "            hierarchy_df[hierarchy_df[\"hierarchy_level\"] == 1][\"contour_idx\"]\n",
    "        )\n",
    "    ]\n",
    "    level_2_contours = [\n",
    "        contours[idx]\n",
    "        for idx in list(\n",
    "            hierarchy_df[hierarchy_df[\"hierarchy_level\"] >= 2][\"contour_idx\"]\n",
    "        )\n",
    "    ]\n",
    "\n",
    "    mask = np.zeros_like(cur_tile_image)\n",
    "    new_mask = cv2.drawContours(\n",
    "        mask, level_1_contours, -1, (255, 255, 255), thickness=cv2.FILLED\n",
    "    )\n",
    "    inside_fill = cv2.drawContours(\n",
    "        new_mask, level_2_contours, -1, (0, 0, 0), thickness=cv2.FILLED\n",
    "    )\n",
    "\n",
    "    # Invert the mask\n",
    "    # inverted_mask = cv2.bitwise_not(new_mask)\n",
    "    inverted_mask = new_mask\n",
    "\n",
    "    # Store the inverted image in the tile_idx_to_letter_image dict\n",
    "    tile_idx_to_letter_image[cur_tile_row.tile_idx] = inverted_mask\n",
    "    \n",
    "    # if idx == 10:\n",
    "    #     break\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can show what the board looks like: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "old_utils.display_images_in_grid([tile_idx_to_letter_image[tile_id] for tile_id in board_tile_df[\"tile_idx\"]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Step 5: Applying OCR to Letters**\n",
    "Now that I've got clean images of the tiles, I need to apply OCR to them. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Declare the reader we're going to use\n",
    "import easyocr\n",
    "\n",
    "reader = easyocr.Reader([\"en\"], gpu=False)\n",
    "\n",
    "# We're going to process all of the tiles in parallel\n",
    "futures = {}\n",
    "result_df_dict = {}\n",
    "with ThreadPoolExecutor() as executor:\n",
    "    # Iterate through all of the rows in the board_tile_df\n",
    "    for row in board_tile_df.itertuples():\n",
    "        cur_tile_idx = row.tile_idx\n",
    "        cur_tile_img = tile_idx_to_letter_image[cur_tile_idx]\n",
    "        futures[cur_tile_idx] = executor.submit(\n",
    "            old_utils.multi_engine_tile_processing, cur_tile_img, reader\n",
    "        )\n",
    "\n",
    "    # Now, we'll collect the results of the futures\n",
    "    for tile_idx, future in tqdm(list(futures.items())):\n",
    "        result_df_dict[tile_idx] = future.result()\n",
    "\n",
    "# Now, we're going to collect the different\n",
    "tile_idx_to_best_prediction = {}\n",
    "for tile_idx, result_df in result_df_dict.items():\n",
    "    tile_idx_to_best_prediction[tile_idx] = old_utils.aggregate_prediction_results(\n",
    "        result_df, min_prediction_confidence=0.6\n",
    "    )\n",
    "\n",
    "# Store these results in a DataFrame\n",
    "board_tiles_with_predictions_df = board_tile_df.copy()\n",
    "\n",
    "board_tiles_with_predictions_df[\"text_prediction\"] = board_tiles_with_predictions_df[\n",
    "    \"tile_idx\"\n",
    "].apply(lambda cur_tile_idx: tile_idx_to_best_prediction[cur_tile_idx][0])\n",
    "\n",
    "board_tiles_with_predictions_df[\n",
    "    \"rotation_prediction\"\n",
    "] = board_tiles_with_predictions_df[\"tile_idx\"].apply(\n",
    "    lambda cur_tile_idx: tile_idx_to_best_prediction[cur_tile_idx][1]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we've done that, we're going to show off the different tiles, as well as the predictions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "row_size = 6\n",
    "lines = []\n",
    "cur_line = []\n",
    "for row in board_tiles_with_predictions_df.itertuples():\n",
    "    cur_line.append(row.text_prediction)\n",
    "    if len(cur_line) == row_size:\n",
    "        lines.append(cur_line)\n",
    "        cur_line = []\n",
    "for line in lines:\n",
    "    print(line)\n",
    "old_utils.display_images_in_grid(\n",
    "    [tile_idx_to_letter_image[tile_id] for tile_id in board_tile_df[\"tile_idx\"]]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NOTES:**\n",
    "- \"I\" tiles don't always seem to be detected. One of them was, but another one wasn't. \n",
    "- The \"block\" tile also isn't detected\n",
    "- There's SOME trouble detecting the letter \"D\" - it sometimes reads them as \"O\". We might want to increase the weight associated with skeletons in those instances - not entirely sure. \n",
    "- It seems to do a decent job at detecting W's over M's, but definitely thinks that \"Z\"s are \"N\"\n",
    "- The function is generally a little slow. I'm not entirely sure *why* that is - probably something with the `easyocr` model being loaded multiple times / not being on CPU.\n",
    "- C can sometimes be mistaken for O.\n",
    "- Y can be mistaken for A. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Step 6:** Constructing the Board Data Structure\n",
    "Now that I've run OCR on all of the letters, I can output the board's data structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
