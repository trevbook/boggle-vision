{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Motivation\n",
    "\n",
    "I want to include some word definitions in the Boggle Vision app. In order to do that, I need to have _some_ local store of all of the definitions. I'll create that in this notebook!\n",
    "\n",
    "I found [this repo that has a JSON verison of the Webster's dictonary](https://github.com/ssvivian/WebstersDictionary) - I'm going to use that in order to fetch the definitions for the words.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup\n",
    "\n",
    "The cells below will set up the rest of the notebook.\n",
    "\n",
    "I'll start by configuring my kernel:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d:\\data\\programming\\boggle-vision\\boggle-vision-prototyping\n"
     ]
    }
   ],
   "source": [
    "# Change the cwd to the parent of the current dir\n",
    "%cd .. \n",
    "\n",
    "# Enable the autoreload extension so that code can change\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, I'm going to run through some import statements:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import statements\n",
    "import json\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, I'm going to load in some important files - namely, the list of allowed words, and the Webster's dictionary.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load in the list of allowed words\n",
    "with open(\"data\\scrabble-dictionary.json\", \"r\") as f:\n",
    "    allowed_words = json.load(f)\n",
    "\n",
    "# Load in the Websters dictionary\n",
    "with open(\"data\\websters-dictionary.json\", \"r\") as f:\n",
    "    websters_dictionary = json.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transforming Data\n",
    "\n",
    "The main thing that I need to do in this notebook: determine which words from the Scrabble dictionary have definitions.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a DataFrame version of the allowed_words list\n",
    "allowed_words_df = pd.DataFrame(allowed_words, columns=[\"word\"])\n",
    "\n",
    "# Make a DataFrame version of the websters_dictionary list\n",
    "websters_dictionary_df = pd.DataFrame.from_records(websters_dictionary)\n",
    "\n",
    "# Drop the \"synonyms\" column from the websters_dictionary_df\n",
    "websters_dictionary_df.drop(columns=[\"synonyms\"], inplace=True)\n",
    "\n",
    "# Make the word column a lower case string\n",
    "websters_dictionary_df[\"word\"] = websters_dictionary_df[\"word\"].str.lower()\n",
    "\n",
    "# Merge the allowed_words_df with the websters_dictionary_df\n",
    "merged_websters_dictionary_df = websters_dictionary_df.merge(\n",
    "    allowed_words_df, on=\"word\", how=\"outer\", indicator=\"exists_in_scrabble_dict\"\n",
    ")\n",
    "\n",
    "\n",
    "def check_if_exists_in_scrabble_dict(row):\n",
    "    \"\"\"\n",
    "    Checks if the word exists in the scrabble dictionary.\n",
    "    \"\"\"\n",
    "    if row[\"exists_in_scrabble_dict\"] == \"both\":\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "\n",
    "merged_websters_dictionary_df[\n",
    "    \"exists_in_scrabble_dict\"\n",
    "] = merged_websters_dictionary_df.apply(check_if_exists_in_scrabble_dict, axis=1)\n",
    "\n",
    "# Add a \"length\" column to the merged_websters_dictionary_df\n",
    "merged_websters_dictionary_df[\"length\"] = merged_websters_dictionary_df[\n",
    "    \"word\"\n",
    "].str.len()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How many of the Scrabble words don't have dictionary definitions?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "exists_in_scrabble_dict\n",
       "False    178693\n",
       "True      60353\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_websters_dictionary_df[\"exists_in_scrabble_dict\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems to be quite a few of them. However: in order to take an aggressive approach to this, I'm just going to drop _every_ word that doesn't have a definition. Also, words under 4 letters long.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pos</th>\n",
       "      <th>word</th>\n",
       "      <th>definitions</th>\n",
       "      <th>exists_in_scrabble_dict</th>\n",
       "      <th>length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>n.</td>\n",
       "      <td>abaca</td>\n",
       "      <td>[The Manila-hemp plant (Musa textilis); also, ...</td>\n",
       "      <td>True</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>adv.</td>\n",
       "      <td>aback</td>\n",
       "      <td>[Toward the back or rear; backward. \"Therewith...</td>\n",
       "      <td>True</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>n.</td>\n",
       "      <td>aback</td>\n",
       "      <td>[An abacus. [Obs.] B. Jonson.]</td>\n",
       "      <td>True</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     pos   word                                        definitions  \\\n",
       "14    n.  abaca  [The Manila-hemp plant (Musa textilis); also, ...   \n",
       "19  adv.  aback  [Toward the back or rear; backward. \"Therewith...   \n",
       "20    n.  aback                     [An abacus. [Obs.] B. Jonson.]   \n",
       "\n",
       "    exists_in_scrabble_dict  length  \n",
       "14                     True       5  \n",
       "19                     True       5  \n",
       "20                     True       5  "
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a filtered version of the merged_websters_dictionary_df\n",
    "filtered_merged_websters_dictionary_df = merged_websters_dictionary_df.query(\n",
    "    \"length >= 4 & exists_in_scrabble_dict == True\"\n",
    ").copy()\n",
    "\n",
    "# Show the first 3 rows of the filtered_merged_websters_dictionary_df\n",
    "filtered_merged_websters_dictionary_df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, I'll work on adding some nicer \"definition\" labels.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dictionary mapping pos tags to the actual part of speech\n",
    "pos_tag_to_label_dict = {\n",
    "    \"n.\": \"noun\",\n",
    "    \"adv.\": \"adverb\",\n",
    "    \"prep.\": \"preposition\",\n",
    "    \"v.\": \"verb\",\n",
    "    \"a.\": \"adjective\",\n",
    "    \"p.\": \"pronoun\",\n",
    "    \"interj.\": \"interjection\",\n",
    "    \"conj.\": \"conjunction\",\n",
    "    \"pron.\": \"pronoun\",\n",
    "}\n",
    "\n",
    "filtered_merged_websters_dictionary_df[\n",
    "    \"pos_label\"\n",
    "] = filtered_merged_websters_dictionary_df[\"pos\"].apply(\n",
    "    lambda x: pos_tag_to_label_dict.get(x, \"unknown\")\n",
    ")\n",
    "\n",
    "# Add a column that contains a string of the first definition\n",
    "filtered_merged_websters_dictionary_df[\n",
    "    \"definition_str\"\n",
    "] = filtered_merged_websters_dictionary_df.apply(lambda row: row.definitions[0], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving Data\n",
    "\n",
    "Now that I've got a trimmed down dictionary, I'm going to save it locally. I'll use this trimmed down file in the production app.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dictionary that will map words to their definitions and part of speech\n",
    "word_to_definition_dict = {\n",
    "    row.word: {\n",
    "        \"pos\": row.pos_label,\n",
    "        \"definition\": row.definition_str,\n",
    "    }\n",
    "    for row in filtered_merged_websters_dictionary_df[\n",
    "        [\"word\", \"pos_label\", \"definition_str\"]\n",
    "    ].itertuples()\n",
    "}\n",
    "\n",
    "# Now, save this dictionary to a json file\n",
    "with open(\"data\\word_to_definition.json\", \"w\") as f:\n",
    "    json.dump(word_to_definition_dict, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
