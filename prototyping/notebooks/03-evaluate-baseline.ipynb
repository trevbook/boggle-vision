{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cell-0",
   "metadata": {},
   "source": [
    "# 03 â€” Evaluate Pretrained Baseline (No Fine-Tuning)\n",
    "\n",
    "**Goal:** Test if the pretrained COCO model works well enough WITHOUT fine-tuning.\n",
    "\n",
    "**Hypothesis:** Fine-tuning on 377 images (23 real) causes catastrophic forgetting.\n",
    "The baseline might already be good enough!\n",
    "\n",
    "**Inputs:**\n",
    "- `yolov8s-seg.pt` â€” Pretrained COCO weights (no fine-tuning)\n",
    "- Real validation images from `data/yolo-seg-board/images/val/`\n",
    "\n",
    "**Outputs:**\n",
    "- Visual predictions on real images\n",
    "- IoU metrics\n",
    "- Detection rate\n",
    "- Decision: fine-tune or use baseline as-is?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-1",
   "metadata": {},
   "source": [
    "## 1. Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from ultralytics import YOLO\n",
    "\n",
    "# Paths\n",
    "PROJECT_ROOT = Path.cwd().parent\n",
    "DATA_DIR = PROJECT_ROOT / \"prototyping/data\"\n",
    "DATASET_DIR = DATA_DIR / \"yolo-seg-board\"\n",
    "VAL_IMG_DIR = DATASET_DIR / \"images\" / \"val\"\n",
    "VAL_LBL_DIR = DATASET_DIR / \"labels\" / \"val\"\n",
    "\n",
    "# Load PRETRAINED model (NO fine-tuning)\n",
    "print(\"Loading pretrained YOLOv8s-seg (COCO weights, no fine-tuning)...\")\n",
    "model = YOLO(\"yolov8s-seg.pt\")\n",
    "print(\"âœ… Model loaded\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-3",
   "metadata": {},
   "source": [
    "## 2. Evaluate on Real Images Only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get ALL validation images (real + synthetic)\n",
    "all_imgs = sorted(VAL_IMG_DIR.glob(\"*.jpg\"))\n",
    "real_imgs = [p for p in all_imgs if p.name.startswith(\"real_\")]\n",
    "synth_imgs = [p for p in all_imgs if p.name.startswith(\"synth_\")]\n",
    "\n",
    "print(f\"Found {len(all_imgs)} total validation images:\")\n",
    "print(f\"  - {len(real_imgs)} real\")\n",
    "print(f\"  - {len(synth_imgs)} synthetic\")\n",
    "\n",
    "# Predict on ALL images\n",
    "results = []\n",
    "for img_path in all_imgs:\n",
    "    pred = model.predict(str(img_path), imgsz=640, conf=0.25, verbose=False)[0]\n",
    "    img_type = \"real\" if img_path.name.startswith(\"real_\") else \"synth\"\n",
    "    results.append((img_path, pred, img_type))\n",
    "\n",
    "print(f\"\\nâœ… Ran predictions on {len(results)} images\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-5",
   "metadata": {},
   "source": [
    "## 3. Visual Inspection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display predictions - sample from both real and synthetic\n",
    "n_real_display = min(len(real_imgs), 4)\n",
    "n_synth_display = min(len(synth_imgs), 12)\n",
    "n_display = n_real_display + n_synth_display\n",
    "\n",
    "# Get sample results\n",
    "real_results = [r for r in results if r[2] == \"real\"][:n_real_display]\n",
    "synth_results = [r for r in results if r[2] == \"synth\"][:n_synth_display]\n",
    "display_results = real_results + synth_results\n",
    "\n",
    "n_cols = 4\n",
    "n_rows = (n_display + n_cols - 1) // n_cols\n",
    "\n",
    "fig, axes = plt.subplots(n_rows, n_cols, figsize=(5 * n_cols, 5 * n_rows))\n",
    "axes = axes.flatten() if n_display > 1 else [axes]\n",
    "\n",
    "for idx, (img_path, pred, img_type) in enumerate(display_results):\n",
    "    annotated = pred.plot()\n",
    "    axes[idx].imshow(cv2.cvtColor(annotated, cv2.COLOR_BGR2RGB))\n",
    "    \n",
    "    # Count detections\n",
    "    n_det = len(pred.boxes) if pred.boxes is not None else 0\n",
    "    conf = pred.boxes.conf[0].item() if n_det > 0 else 0.0\n",
    "    \n",
    "    # Show detected class\n",
    "    cls_name = \"none\"\n",
    "    if n_det > 0:\n",
    "        cls_id = int(pred.boxes.cls[0].item())\n",
    "        cls_name = pred.names[cls_id]\n",
    "    \n",
    "    type_label = \"[REAL]\" if img_type == \"real\" else \"[SYNTH]\"\n",
    "    axes[idx].set_title(f\"{type_label} {img_path.name[:20]}\\n{cls_name} (conf={conf:.2f})\", fontsize=8)\n",
    "    axes[idx].axis(\"off\")\n",
    "\n",
    "for idx in range(n_display, len(axes)):\n",
    "    axes[idx].set_visible(False)\n",
    "\n",
    "plt.suptitle(f\"Pretrained Baseline Predictions (No Fine-Tuning)\\n{len(real_results)} real + {len(synth_results)} synthetic samples\", fontsize=14, fontweight=\"bold\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-7",
   "metadata": {},
   "source": [
    "## 4. Compute IoU Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_mask_iou(pred_mask, gt_polygon, img_shape):\n",
    "    \"\"\"Compute IoU between predicted mask and ground truth polygon.\"\"\"\n",
    "    h, w = img_shape[:2]\n",
    "    \n",
    "    # Create GT mask\n",
    "    gt_mask = np.zeros((h, w), dtype=np.uint8)\n",
    "    cv2.fillPoly(gt_mask, [gt_polygon.reshape(-1, 1, 2)], 1)\n",
    "    \n",
    "    # Resize pred mask to image size\n",
    "    if pred_mask.shape != (h, w):\n",
    "        pred_mask = cv2.resize(\n",
    "            pred_mask.astype(np.uint8), (w, h), \n",
    "            interpolation=cv2.INTER_NEAREST\n",
    "        )\n",
    "    \n",
    "    # Compute IoU\n",
    "    intersection = np.logical_and(pred_mask, gt_mask).sum()\n",
    "    union = np.logical_or(pred_mask, gt_mask).sum()\n",
    "    return intersection / union if union > 0 else 0.0\n",
    "\n",
    "# Compute metrics - separate by real vs synthetic\n",
    "real_ious = []\n",
    "real_confs = []\n",
    "real_detected = 0\n",
    "\n",
    "synth_ious = []\n",
    "synth_confs = []\n",
    "synth_detected = 0\n",
    "\n",
    "for img_path, pred, img_type in results:\n",
    "    # Load GT label\n",
    "    lbl_path = VAL_LBL_DIR / f\"{img_path.stem}.txt\"\n",
    "    if not lbl_path.exists():\n",
    "        continue\n",
    "    \n",
    "    label_text = lbl_path.read_text().strip().split()\n",
    "    coords = [float(x) for x in label_text[1:]]\n",
    "    \n",
    "    img = cv2.imread(str(img_path))\n",
    "    h, w = img.shape[:2]\n",
    "    gt_pts = np.array(\n",
    "        [[coords[i] * w, coords[i + 1] * h] for i in range(0, len(coords), 2)],\n",
    "        dtype=np.int32,\n",
    "    )\n",
    "    \n",
    "    # Check if detected\n",
    "    if pred.masks is not None and len(pred.masks) > 0:\n",
    "        pred_mask = pred.masks.data[0].cpu().numpy()\n",
    "        iou = compute_mask_iou(pred_mask, gt_pts, (h, w))\n",
    "        conf = pred.boxes.conf[0].item()\n",
    "        \n",
    "        if img_type == \"real\":\n",
    "            real_ious.append(iou)\n",
    "            real_confs.append(conf)\n",
    "            real_detected += 1\n",
    "        else:\n",
    "            synth_ious.append(iou)\n",
    "            synth_confs.append(conf)\n",
    "            synth_detected += 1\n",
    "    else:\n",
    "        if img_type == \"real\":\n",
    "            real_ious.append(0.0)\n",
    "            real_confs.append(0.0)\n",
    "        else:\n",
    "            synth_ious.append(0.0)\n",
    "            synth_confs.append(0.0)\n",
    "\n",
    "# Compute totals\n",
    "all_ious = real_ious + synth_ious\n",
    "all_confs = real_confs + synth_confs\n",
    "total_detected = real_detected + synth_detected\n",
    "total_images = len(real_ious) + len(synth_ious)\n",
    "\n",
    "# Print summary\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"BASELINE MODEL PERFORMANCE (NO FINE-TUNING)\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(f\"\\nðŸ“Š OVERALL:\")\n",
    "print(f\"  Detection Rate: {total_detected}/{total_images} ({100*total_detected/total_images:.1f}%)\")\n",
    "print(f\"  Mean IoU: {np.mean(all_ious):.4f}\")\n",
    "print(f\"  Mean Confidence: {np.mean([c for c in all_confs if c > 0]):.4f}\" if total_detected > 0 else \"  Mean Confidence: N/A\")\n",
    "print(f\"  IoU > 0.7: {sum(1 for iou in all_ious if iou > 0.7)}/{len(all_ious)} ({100*sum(1 for iou in all_ious if iou > 0.7)/len(all_ious):.1f}%)\")\n",
    "\n",
    "print(f\"\\nðŸ“Š REAL IMAGES ({len(real_ious)} images):\")\n",
    "print(f\"  Detection Rate: {real_detected}/{len(real_ious)} ({100*real_detected/len(real_ious):.1f}%)\")\n",
    "print(f\"  Mean IoU: {np.mean(real_ious):.4f}\")\n",
    "print(f\"  Mean Confidence: {np.mean([c for c in real_confs if c > 0]):.4f}\" if real_detected > 0 else \"  Mean Confidence: N/A\")\n",
    "print(f\"  IoU > 0.7: {sum(1 for iou in real_ious if iou > 0.7)}/{len(real_ious)} ({100*sum(1 for iou in real_ious if iou > 0.7)/len(real_ious):.1f}%)\")\n",
    "\n",
    "print(f\"\\nðŸ“Š SYNTHETIC IMAGES ({len(synth_ious)} images):\")\n",
    "print(f\"  Detection Rate: {synth_detected}/{len(synth_ious)} ({100*synth_detected/len(synth_ious):.1f}%)\")\n",
    "print(f\"  Mean IoU: {np.mean(synth_ious):.4f}\")\n",
    "print(f\"  Mean Confidence: {np.mean([c for c in synth_confs if c > 0]):.4f}\" if synth_detected > 0 else \"  Mean Confidence: N/A\")\n",
    "print(f\"  IoU > 0.7: {sum(1 for iou in synth_ious if iou > 0.7)}/{len(synth_ious)} ({100*sum(1 for iou in synth_ious if iou > 0.7)/len(synth_ious):.1f}%)\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"COMPARISON TO FINE-TUNED MODELS\")\n",
    "print(\"=\"*70)\n",
    "print(f\"Baseline (no tuning):  Overall IoU = {np.mean(all_ious):.4f}, Detection = {100*total_detected/total_images:.1f}%\")\n",
    "print(f\"                       Real IoU = {np.mean(real_ious):.4f}, Synth IoU = {np.mean(synth_ious):.4f}\")\n",
    "print(f\"Fine-tuned YOLOv8s:    Overall IoU = 0.403,  Real IoU = 0.358, Synth IoU = 0.406\")\n",
    "print(f\"Fine-tuned YOLOv8n:    Overall IoU = 0.329,  Real IoU = 0.523, Synth IoU = 0.318\")\n",
    "\n",
    "# Decision logic\n",
    "if np.mean(all_ious) > 0.7 and total_detected / total_images > 0.8:\n",
    "    print(\"\\nâœ… BASELINE WINS! Skip fine-tuning and use pretrained model.\")\n",
    "elif np.mean(all_ious) > 0.5:\n",
    "    print(\"\\nâš ï¸  BASELINE IS DECENT. Consider minimal fine-tuning (freeze=24, lr=0.0001).\")\n",
    "else:\n",
    "    print(\"\\nâŒ BASELINE NEEDS IMPROVEMENT. Collect more real data or try extreme freezing.\")\n",
    "\n",
    "# Histogram comparison\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "axes[0].hist(real_ious, bins=20, edgecolor='black', alpha=0.7, color='coral')\n",
    "axes[0].axvline(np.mean(real_ious), color='red', linestyle='--', linewidth=2, label=f'Mean: {np.mean(real_ious):.3f}')\n",
    "axes[0].set_xlabel('IoU')\n",
    "axes[0].set_ylabel('Count')\n",
    "axes[0].set_title(f'Real Images (n={len(real_ious)})')\n",
    "axes[0].set_xlim(0, 1)\n",
    "axes[0].legend()\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "axes[1].hist(synth_ious, bins=20, edgecolor='black', alpha=0.7, color='lightblue')\n",
    "axes[1].axvline(np.mean(synth_ious), color='blue', linestyle='--', linewidth=2, label=f'Mean: {np.mean(synth_ious):.3f}')\n",
    "axes[1].set_xlabel('IoU')\n",
    "axes[1].set_ylabel('Count')\n",
    "axes[1].set_title(f'Synthetic Images (n={len(synth_ious)})')\n",
    "axes[1].set_xlim(0, 1)\n",
    "axes[1].legend()\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.suptitle('IoU Distribution: Real vs Synthetic (Baseline Model)', fontsize=14, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-9",
   "metadata": {},
   "source": [
    "## 5. Check What COCO Class Is Being Detected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count detected classes\n",
    "from collections import Counter\n",
    "\n",
    "detected_classes = []\n",
    "for img_path, pred, img_type in results:\n",
    "    if pred.boxes is not None and len(pred.boxes) > 0:\n",
    "        cls_id = int(pred.boxes.cls[0].item())\n",
    "        cls_name = pred.names[cls_id]\n",
    "        detected_classes.append(cls_name)\n",
    "\n",
    "class_counts = Counter(detected_classes)\n",
    "\n",
    "print(\"\\nðŸ” What COCO Classes Are Detected?\")\n",
    "print(\"=\"*40)\n",
    "for cls_name, count in class_counts.most_common():\n",
    "    print(f\"  {cls_name}: {count}x\")\n",
    "\n",
    "print(\"\\nðŸ’¡ This tells us which COCO features are transferring to boards.\")\n",
    "print(\"   Common matches: laptop, book, cell phone, keyboard, remote\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-11",
   "metadata": {},
   "source": [
    "## 6. Decision: Fine-Tune or Use Baseline?\n",
    "\n",
    "**If baseline IoU > 0.7 and detection > 80%:**\n",
    "- âœ… Use pretrained model as-is (no fine-tuning)\n",
    "- Save baseline weights for deployment\n",
    "- Maybe just tune confidence threshold\n",
    "\n",
    "**If baseline IoU 0.5-0.7:**\n",
    "- Try extreme freezing: `freeze=24` layers\n",
    "- Use tiny learning rate: `lr0=0.0001`\n",
    "- Collect 50+ more real training images\n",
    "\n",
    "**If baseline IoU < 0.5:**\n",
    "- Collect 200+ real images\n",
    "- Try different augmentation\n",
    "- Consider using a different architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e3d5870",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
